{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8UEb9OHI4gNS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from langdetect import detect\n",
        "from urllib.parse import urlsplit\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OutputSentiment\n",
              "negative    2528\n",
              "positive    2472\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"../Dataset/IMDB Dataset.csv\")\n",
        "df.head()\n",
        "df = df.rename(columns={'review': 'OriginalReviews'})\n",
        "df = df.rename(columns={'sentiment': 'OutputSentiment'})\n",
        "df_subset = df.sample(n=5000).reset_index(drop=True)\n",
        "df_subset.head()\n",
        "df_subset['OutputSentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#lowercase\n",
        "df_subset[\"OriginalReviews\"]=df_subset[\"OriginalReviews\"].apply(lambda x:x.lower())\n",
        "\n",
        "#Remove punctuations\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
        "\n",
        "# Remove numbers from the 'OriginalReviewss' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].str.replace('\\d+', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to remove stopwords from a text\n",
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "# Apply the remove_stopwords function to the 'OriginalReviews' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_urls(text):\n",
        "    # Define a regular expression pattern to match URLs\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "\n",
        "    # Find all matches in the text\n",
        "    urls = re.findall(url_pattern, text)\n",
        "\n",
        "    # Remove URLs from the text\n",
        "    text_without_urls = re.sub(url_pattern, '', text)\n",
        "\n",
        "    return text_without_urls\n",
        "\n",
        "# Example usage\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdidd\\AppData\\Local\\Temp\\ipykernel_14584\\3731208440.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, 'html.parser')\n"
          ]
        }
      ],
      "source": [
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    return soup.get_text()\n",
        "\n",
        "df_subset[\"OriginalReviews\"] = df_subset[\"OriginalReviews\"].apply(remove_html_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_extra_whitespaces(text):\n",
        "    # Use regular expression to replace multiple whitespaces with a single space\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_extra_whitespaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_non_english(text):\n",
        "    try:\n",
        "        return detect(text) == 'en'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Create a boolean mask for non-English OriginalReviewss\n",
        "mask = df_subset['OriginalReviews'].apply(filter_non_english)\n",
        "\n",
        "# Create a new DataFrame containing only English OriginalReviewss\n",
        "df_subset = df_subset[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to get the part of speech for WordNet lemmatizer\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # Default to noun if the part of speech is not found\n",
        "\n",
        "# Function to lemmatize a text\n",
        "def lemmatize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply lemmatization to the 'text' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yesterday watch tv production disappoint br br...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>best animate movie ever make film explores vas...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>happen catch suppose horror flick late one fri...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>waste energy money waste talent be br br emili...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>show demonstrate depths uk tv prewatershed dra...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>movie get 1 ca nt give zero weak tummy nt watc...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>saw trailer movie 70 s barely 16 view another ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>movie s premise spooky woman get pregnant kiss...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>curiously rene russo s eye mouth buddy gorilla...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>busy phillips put one hell performance comedic...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment\n",
              "0     yesterday watch tv production disappoint br br...        negative\n",
              "1     best animate movie ever make film explores vas...        positive\n",
              "2     happen catch suppose horror flick late one fri...        negative\n",
              "3     waste energy money waste talent be br br emili...        negative\n",
              "4     show demonstrate depths uk tv prewatershed dra...        negative\n",
              "...                                                 ...             ...\n",
              "4995  movie get 1 ca nt give zero weak tummy nt watc...        negative\n",
              "4996  saw trailer movie 70 s barely 16 view another ...        positive\n",
              "4997  movie s premise spooky woman get pregnant kiss...        negative\n",
              "4998  curiously rene russo s eye mouth buddy gorilla...        negative\n",
              "4999  busy phillips put one hell performance comedic...        positive\n",
              "\n",
              "[4996 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_subset.to_csv(\"../csv/Preprocessed_data.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction Using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed = pd.read_csv('../csv/Preprocessed_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_features_to_keep = 13000\n",
        "\n",
        "# Create a pipeline with TfidfVectorizer and SelectKBest\n",
        "pipeline = make_pipeline(TfidfVectorizer(), SelectKBest(f_classif, k=num_features_to_keep))\n",
        "\n",
        "# Fit and transform your data\n",
        "X_transformed = pipeline.fit_transform(preprocessed['OriginalReviews'], preprocessed['OutputSentiment'])\n",
        "\n",
        "# Get the selected feature names\n",
        "selected_feature_names = pipeline.named_steps['tfidfvectorizer'].get_feature_names_out()[pipeline.named_steps['selectkbest'].get_support()]\n",
        "\n",
        "# Create a DataFrame with the selected features\n",
        "selected_features_df = pd.DataFrame(X_transformed.toarray(), columns=selected_feature_names)\n",
        "\n",
        "# Concatenate the existing DataFrame with the new selected features DataFrame\n",
        "tfidf_df_13k = pd.concat([preprocessed, selected_features_df], axis=1)\n",
        "\n",
        "tfidf_df_13k.head()\n",
        "\n",
        "tfidf_df_13k.to_csv(\"../csv/tfidf_df_13k.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CONNOTATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download the VADER lexicon (run this once)\n",
        "nltk.download('vader_lexicon')\n",
        "delimiter = '\\t'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "positive = pd.read_csv(r'..\\Connotations\\positive-words.txt', sep=delimiter, names=['words'])\n",
        "negative = pd.read_csv(r'..\\Connotations\\negative-words.txt', sep=delimiter, names=['words'])\n",
        "connotations = pd.read_csv(r\"..\\Connotations\\connotations.csv\")\n",
        "\n",
        "word_emotion_map = dict(zip(connotations['word'], connotations['emotion']))\n",
        "\n",
        "def update_counts(review):\n",
        "    positive_count = sum(1 for word in review.split() if word in word_emotion_map and word_emotion_map[word] == 'positive')\n",
        "    negative_count = sum(1 for word in review.split() if word in word_emotion_map and word_emotion_map[word] == 'negative')\n",
        "    return positive_count, negative_count\n",
        "\n",
        "tfidf_df_13k[['Positive_Connotation_Count', 'Negative_Connotation_Count']] = tfidf_df_13k['OriginalReviews'].apply(update_counts).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load positive and negative words from files\n",
        "positive_words_df = pd.read_csv(r'..\\Connotations\\positive-words.txt', header=None, names=['words'])\n",
        "negative_words_df = pd.read_csv(r'..\\Connotations\\negative-words.txt', header=None, names=['words'])\n",
        "\n",
        "# Convert DataFrame columns to sets\n",
        "positive_words = set(positive_words_df['words'].tolist())\n",
        "negative_words = set(negative_words_df['words'].tolist())\n",
        "\n",
        "# Assuming 'tfidf_df_13k' is your DataFrame\n",
        "# Define a function to update counts based on positive and negative words\n",
        "def update_word_counts(review):\n",
        "    positive_count = sum(1 for word in review.split() if word in positive_words)\n",
        "    negative_count = sum(1 for word in review.split() if word in negative_words)\n",
        "    return positive_count, negative_count\n",
        "\n",
        "# Apply the function to the 'OriginalReviews' column and unpack the result into two new columns\n",
        "tfidf_df_13k[['Positive_Word_Count', 'Negative_Word_Count']] = tfidf_df_13k['OriginalReviews'].apply(update_word_counts).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "# Use VADER for sentiment analysis\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(review):\n",
        "    scores = sid.polarity_scores(review)\n",
        "    return scores['pos'] *100, scores['neg'] * 100\n",
        "\n",
        "# Apply the function to the 'OriginalReviews' column and unpack the result into two new columns\n",
        "tfidf_df_13k[['Positive_VADER_Count', 'Negative_VADER_Count']] = tfidf_df_13k['OriginalReviews'].apply(vader_sentiment).tolist()\n",
        "\n",
        "tfidf_df_13k.to_csv(\"../csv/tfidf_df_13k_connotations_vader.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = tfidf_df_13k.iloc[4993]['OriginalReviews']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_df_13k = pd.read_csv(\"../csv/tfidf_df_13k.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_df_13k_connotations = pd.read_csv('../csv/tfidf_df_13k_connotations_vader.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1PSHjJbnJcoJ"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Unnamed: 0'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tfidf_df_13k_connotations \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_df_13k_connotations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5570\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5574\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5575\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4785\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4827\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4825\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4827\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4828\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4830\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
          ]
        }
      ],
      "source": [
        "tfidf_df_13k_connotations = tfidf_df_13k_connotations.drop('Unnamed: 0',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>010</th>\n",
              "      <th>06</th>\n",
              "      <th>10</th>\n",
              "      <th>10000</th>\n",
              "      <th>1000000</th>\n",
              "      <th>100th</th>\n",
              "      <th>...</th>\n",
              "      <th>zuniga</th>\n",
              "      <th>zurer</th>\n",
              "      <th>zuzzzuzz</th>\n",
              "      <th>zy</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yesterday watch tv production disappoint br br...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>9.9</td>\n",
              "      <td>27.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>best animate movie ever make film explores vas...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>20.5</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>happen catch suppose horror flick late one fri...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>waste energy money waste talent be br br emili...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>23.1</td>\n",
              "      <td>15.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>show demonstrate depths uk tv prewatershed dra...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>13.8</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>movie get 1 ca nt give zero weak tummy nt watc...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>19.6</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>saw trailer movie 70 s barely 16 view another ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>34.1</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>movie s premise spooky woman get pregnant kiss...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>10.4</td>\n",
              "      <td>21.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>curiously rene russo s eye mouth buddy gorilla...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>16.5</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>busy phillips put one hell performance comedic...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>19.6</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows × 13008 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment  007  \\\n",
              "0     yesterday watch tv production disappoint br br...        negative  0.0   \n",
              "1     best animate movie ever make film explores vas...        positive  0.0   \n",
              "2     happen catch suppose horror flick late one fri...        negative  0.0   \n",
              "3     waste energy money waste talent be br br emili...        negative  0.0   \n",
              "4     show demonstrate depths uk tv prewatershed dra...        negative  0.0   \n",
              "...                                                 ...             ...  ...   \n",
              "4991  movie get 1 ca nt give zero weak tummy nt watc...        negative  0.0   \n",
              "4992  saw trailer movie 70 s barely 16 view another ...        positive  0.0   \n",
              "4993  movie s premise spooky woman get pregnant kiss...        negative  0.0   \n",
              "4994  curiously rene russo s eye mouth buddy gorilla...        negative  0.0   \n",
              "4995  busy phillips put one hell performance comedic...        positive  0.0   \n",
              "\n",
              "       01  010   06   10  10000  1000000  100th  ...  zuniga  zurer  zuzzzuzz  \\\n",
              "0     0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "1     0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "2     0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "3     0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "4     0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "...   ...  ...  ...  ...    ...      ...    ...  ...     ...    ...       ...   \n",
              "4991  0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "4992  0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "4993  0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "4994  0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "4995  0.0  0.0  0.0  0.0    0.0      0.0    0.0  ...     0.0    0.0       0.0   \n",
              "\n",
              "       zy  Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0     0.0                          24                          31   \n",
              "1     0.0                          37                          21   \n",
              "2     0.0                          23                          26   \n",
              "3     0.0                          27                          27   \n",
              "4     0.0                          16                          19   \n",
              "...   ...                         ...                         ...   \n",
              "4991  0.0                          25                          18   \n",
              "4992  0.0                          37                          26   \n",
              "4993  0.0                          15                          22   \n",
              "4994  0.0                          47                          48   \n",
              "4995  0.0                          19                          11   \n",
              "\n",
              "      Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                       4                   13                   9.9   \n",
              "1                       5                    4                  20.5   \n",
              "2                       3                    7                  11.0   \n",
              "3                      10                   10                  23.1   \n",
              "4                       3                    7                  13.8   \n",
              "...                   ...                  ...                   ...   \n",
              "4991                    6                    6                  19.6   \n",
              "4992                   12                    3                  34.1   \n",
              "4993                    2                    9                  10.4   \n",
              "4994                   11                   11                  16.5   \n",
              "4995                    4                    3                  19.6   \n",
              "\n",
              "      Negative_VADER_Count  \n",
              "0                     27.6  \n",
              "1                     10.8  \n",
              "2                     21.6  \n",
              "3                     15.8  \n",
              "4                     18.2  \n",
              "...                    ...  \n",
              "4991                  16.0  \n",
              "4992                   3.1  \n",
              "4993                  21.8  \n",
              "4994                  10.1  \n",
              "4995                  30.0  \n",
              "\n",
              "[4996 rows x 13008 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_df_13k_connotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "uTeIZqyGNoLJ",
        "outputId": "ec0a348c-7c08-45a6-a607-4fe270099f03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>010</th>\n",
              "      <th>06</th>\n",
              "      <th>10</th>\n",
              "      <th>10000</th>\n",
              "      <th>1000000</th>\n",
              "      <th>100th</th>\n",
              "      <th>1010</th>\n",
              "      <th>...</th>\n",
              "      <th>zp</th>\n",
              "      <th>zsigmond</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zuf</th>\n",
              "      <th>zula</th>\n",
              "      <th>zuniga</th>\n",
              "      <th>zurer</th>\n",
              "      <th>zuzzzuzz</th>\n",
              "      <th>zy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  OutputSentiment  007   01  010   06   10  10000  1000000  100th  1010  ...  \\\n",
              "0        negative  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0  ...   \n",
              "1        positive  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0  ...   \n",
              "2        negative  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0  ...   \n",
              "3        negative  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0  ...   \n",
              "4        negative  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0  ...   \n",
              "\n",
              "    zp  zsigmond   zu  zucker  zuf  zula  zuniga  zurer  zuzzzuzz   zy  \n",
              "0  0.0       0.0  0.0     0.0  0.0   0.0     0.0    0.0       0.0  0.0  \n",
              "1  0.0       0.0  0.0     0.0  0.0   0.0     0.0    0.0       0.0  0.0  \n",
              "2  0.0       0.0  0.0     0.0  0.0   0.0     0.0    0.0       0.0  0.0  \n",
              "3  0.0       0.0  0.0     0.0  0.0   0.0     0.0    0.0       0.0  0.0  \n",
              "4  0.0       0.0  0.0     0.0  0.0   0.0     0.0    0.0       0.0  0.0  \n",
              "\n",
              "[5 rows x 13001 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_statistical = tfidf_df_13k_connotations.drop(columns=['OriginalReviews','Positive_Connotation_Count','Negative_Connotation_Count','Positive_Word_Count','Negative_Word_Count','Positive_VADER_Count','Negative_VADER_Count'], axis=1)\n",
        "df_statistical.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dd-FWJp3N_ug"
      },
      "outputs": [],
      "source": [
        "label = LabelEncoder()\n",
        "df_statistical['OutputSentiment'] = label.fit_transform(df_statistical['OutputSentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CHI SQAURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>007</th>\n",
              "      <th>010</th>\n",
              "      <th>06</th>\n",
              "      <th>10000</th>\n",
              "      <th>1000000</th>\n",
              "      <th>1010</th>\n",
              "      <th>1015</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>120</th>\n",
              "      <th>...</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zuf</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>9.9</td>\n",
              "      <td>27.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>20.5</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>23.1</td>\n",
              "      <td>15.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>13.8</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   007  010   06  10000  1000000  1010  1015   11  110  120  ...  zoo  zorro  \\\n",
              "0  0.0  0.0  0.0    0.0      0.0   0.0   0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
              "1  0.0  0.0  0.0    0.0      0.0   0.0   0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
              "2  0.0  0.0  0.0    0.0      0.0   0.0   0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
              "3  0.0  0.0  0.0    0.0      0.0   0.0   0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
              "4  0.0  0.0  0.0    0.0      0.0   0.0   0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
              "\n",
              "    zu  zuf  Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0  0.0  0.0                          24                          31   \n",
              "1  0.0  0.0                          37                          21   \n",
              "2  0.0  0.0                          23                          26   \n",
              "3  0.0  0.0                          27                          27   \n",
              "4  0.0  0.0                          16                          19   \n",
              "\n",
              "   Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                    4                   13                   9.9   \n",
              "1                    5                    4                  20.5   \n",
              "2                    3                    7                  11.0   \n",
              "3                   10                   10                  23.1   \n",
              "4                    3                    7                  13.8   \n",
              "\n",
              "   Negative_VADER_Count  \n",
              "0                  27.6  \n",
              "1                  10.8  \n",
              "2                  21.6  \n",
              "3                  15.8  \n",
              "4                  18.2  \n",
              "\n",
              "[5 rows x 5006 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This will get the top 5000 relavant features out of the sample\n",
        "chi2_selector = SelectKBest(chi2, k=5000)\n",
        "\n",
        "# This will transform the dataset i.e, it will reduce the dimensions by just considering the relavant features only\n",
        "X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "y = df_statistical['OutputSentiment']\n",
        "X_5000 = chi2_selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "\n",
        "chisq_5k = X[selected_feature_names]\n",
        "chisq_5k.head()\n",
        "\n",
        "chisq_5k = pd.concat([chisq_5k,tfidf_df_13k_connotations.iloc[:, -6:]],axis=1)\n",
        "chisq_5k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>010</th>\n",
              "      <th>06</th>\n",
              "      <th>10</th>\n",
              "      <th>10000</th>\n",
              "      <th>1000000</th>\n",
              "      <th>100th</th>\n",
              "      <th>1010</th>\n",
              "      <th>1015</th>\n",
              "      <th>...</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zuf</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>9.9</td>\n",
              "      <td>27.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>20.5</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>23.1</td>\n",
              "      <td>15.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>13.8</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   007   01  010   06   10  10000  1000000  100th  1010  1015  ...  zoo  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "\n",
              "   zorro   zu  zuf  Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0    0.0  0.0  0.0                          24                          31   \n",
              "1    0.0  0.0  0.0                          37                          21   \n",
              "2    0.0  0.0  0.0                          23                          26   \n",
              "3    0.0  0.0  0.0                          27                          27   \n",
              "4    0.0  0.0  0.0                          16                          19   \n",
              "\n",
              "   Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                    4                   13                   9.9   \n",
              "1                    5                    4                  20.5   \n",
              "2                    3                    7                  11.0   \n",
              "3                   10                   10                  23.1   \n",
              "4                    3                    7                  13.8   \n",
              "\n",
              "   Negative_VADER_Count  \n",
              "0                  27.6  \n",
              "1                  10.8  \n",
              "2                  21.6  \n",
              "3                  15.8  \n",
              "4                  18.2  \n",
              "\n",
              "[5 rows x 8006 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This will get the top 5000 relavant features out of the sample\n",
        "chi2_selector = SelectKBest(chi2, k=8000)\n",
        "\n",
        "# This will transform the dataset i.e, it will reduce the dimensions by just considering the relavant features only\n",
        "X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "y = df_statistical['OutputSentiment']\n",
        "X_8000 = chi2_selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "\n",
        "chisq_8k = X[selected_feature_names]\n",
        "chisq_8k.head()\n",
        "\n",
        "chisq_8k = pd.concat([chisq_8k,tfidf_df_13k_connotations.iloc[:, -6:]],axis=1)\n",
        "chisq_8k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>010</th>\n",
              "      <th>06</th>\n",
              "      <th>10</th>\n",
              "      <th>10000</th>\n",
              "      <th>1000000</th>\n",
              "      <th>100th</th>\n",
              "      <th>1010</th>\n",
              "      <th>1015</th>\n",
              "      <th>...</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zuf</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>9.9</td>\n",
              "      <td>27.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>20.5</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>23.1</td>\n",
              "      <td>15.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>13.8</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>19.6</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>34.1</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>10.4</td>\n",
              "      <td>21.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>16.5</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>19.6</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows × 8006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      007   01  010   06   10  10000  1000000  100th  1010  1015  ...  zoo  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "...   ...  ...  ...  ...  ...    ...      ...    ...   ...   ...  ...  ...   \n",
              "4991  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4992  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4993  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4994  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4995  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "\n",
              "      zorro   zu  zuf  Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0       0.0  0.0  0.0                          24                          31   \n",
              "1       0.0  0.0  0.0                          37                          21   \n",
              "2       0.0  0.0  0.0                          23                          26   \n",
              "3       0.0  0.0  0.0                          27                          27   \n",
              "4       0.0  0.0  0.0                          16                          19   \n",
              "...     ...  ...  ...                         ...                         ...   \n",
              "4991    0.0  0.0  0.0                          25                          18   \n",
              "4992    0.0  0.0  0.0                          37                          26   \n",
              "4993    0.0  0.0  0.0                          15                          22   \n",
              "4994    0.0  0.0  0.0                          47                          48   \n",
              "4995    0.0  0.0  0.0                          19                          11   \n",
              "\n",
              "      Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                       4                   13                   9.9   \n",
              "1                       5                    4                  20.5   \n",
              "2                       3                    7                  11.0   \n",
              "3                      10                   10                  23.1   \n",
              "4                       3                    7                  13.8   \n",
              "...                   ...                  ...                   ...   \n",
              "4991                    6                    6                  19.6   \n",
              "4992                   12                    3                  34.1   \n",
              "4993                    2                    9                  10.4   \n",
              "4994                   11                   11                  16.5   \n",
              "4995                    4                    3                  19.6   \n",
              "\n",
              "      Negative_VADER_Count  \n",
              "0                     27.6  \n",
              "1                     10.8  \n",
              "2                     21.6  \n",
              "3                     15.8  \n",
              "4                     18.2  \n",
              "...                    ...  \n",
              "4991                  16.0  \n",
              "4992                   3.1  \n",
              "4993                  21.8  \n",
              "4994                  10.1  \n",
              "4995                  30.0  \n",
              "\n",
              "[4996 rows x 8006 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chisq_8k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming chisq_8k is your DataFrame\n",
        "columns_to_normalize = ['Positive_Connotation_Count', 'Negative_Connotation_Count', \n",
        "                         'Positive_Word_Count', 'Negative_Word_Count', \n",
        "                         'Positive_VADER_Count', 'Negative_VADER_Count']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "chisq_8k[columns_to_normalize] = scaler.fit_transform(chisq_8k[columns_to_normalize])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>010</th>\n",
              "      <th>06</th>\n",
              "      <th>10</th>\n",
              "      <th>10000</th>\n",
              "      <th>1000000</th>\n",
              "      <th>100th</th>\n",
              "      <th>1010</th>\n",
              "      <th>1015</th>\n",
              "      <th>...</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zuf</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085366</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.054795</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.148872</td>\n",
              "      <td>0.434646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138211</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.054795</td>\n",
              "      <td>0.308271</td>\n",
              "      <td>0.170079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.081301</td>\n",
              "      <td>0.108696</td>\n",
              "      <td>0.041096</td>\n",
              "      <td>0.095890</td>\n",
              "      <td>0.165414</td>\n",
              "      <td>0.340157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.113043</td>\n",
              "      <td>0.136986</td>\n",
              "      <td>0.136986</td>\n",
              "      <td>0.347368</td>\n",
              "      <td>0.248819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052846</td>\n",
              "      <td>0.078261</td>\n",
              "      <td>0.041096</td>\n",
              "      <td>0.095890</td>\n",
              "      <td>0.207519</td>\n",
              "      <td>0.286614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.089431</td>\n",
              "      <td>0.073913</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.294737</td>\n",
              "      <td>0.251969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138211</td>\n",
              "      <td>0.108696</td>\n",
              "      <td>0.164384</td>\n",
              "      <td>0.041096</td>\n",
              "      <td>0.512782</td>\n",
              "      <td>0.048819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.091304</td>\n",
              "      <td>0.027397</td>\n",
              "      <td>0.123288</td>\n",
              "      <td>0.156391</td>\n",
              "      <td>0.343307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.178862</td>\n",
              "      <td>0.204348</td>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.248120</td>\n",
              "      <td>0.159055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.054795</td>\n",
              "      <td>0.041096</td>\n",
              "      <td>0.294737</td>\n",
              "      <td>0.472441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows × 8006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      007   01  010   06   10  10000  1000000  100th  1010  1015  ...  zoo  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "...   ...  ...  ...  ...  ...    ...      ...    ...   ...   ...  ...  ...   \n",
              "4991  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4992  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4993  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4994  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "4995  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0   0.0   0.0  ...  0.0   \n",
              "\n",
              "      zorro   zu  zuf  Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0       0.0  0.0  0.0                    0.085366                    0.130435   \n",
              "1       0.0  0.0  0.0                    0.138211                    0.086957   \n",
              "2       0.0  0.0  0.0                    0.081301                    0.108696   \n",
              "3       0.0  0.0  0.0                    0.097561                    0.113043   \n",
              "4       0.0  0.0  0.0                    0.052846                    0.078261   \n",
              "...     ...  ...  ...                         ...                         ...   \n",
              "4991    0.0  0.0  0.0                    0.089431                    0.073913   \n",
              "4992    0.0  0.0  0.0                    0.138211                    0.108696   \n",
              "4993    0.0  0.0  0.0                    0.048780                    0.091304   \n",
              "4994    0.0  0.0  0.0                    0.178862                    0.204348   \n",
              "4995    0.0  0.0  0.0                    0.065041                    0.043478   \n",
              "\n",
              "      Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                0.054795             0.178082              0.148872   \n",
              "1                0.068493             0.054795              0.308271   \n",
              "2                0.041096             0.095890              0.165414   \n",
              "3                0.136986             0.136986              0.347368   \n",
              "4                0.041096             0.095890              0.207519   \n",
              "...                   ...                  ...                   ...   \n",
              "4991             0.082192             0.082192              0.294737   \n",
              "4992             0.164384             0.041096              0.512782   \n",
              "4993             0.027397             0.123288              0.156391   \n",
              "4994             0.150685             0.150685              0.248120   \n",
              "4995             0.054795             0.041096              0.294737   \n",
              "\n",
              "      Negative_VADER_Count  \n",
              "0                 0.434646  \n",
              "1                 0.170079  \n",
              "2                 0.340157  \n",
              "3                 0.248819  \n",
              "4                 0.286614  \n",
              "...                    ...  \n",
              "4991              0.251969  \n",
              "4992              0.048819  \n",
              "4993              0.343307  \n",
              "4994              0.159055  \n",
              "4995              0.472441  \n",
              "\n",
              "[4996 rows x 8006 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chisq_8k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CHI SQAURE CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes Cross-Validation Scores:\n",
            "[0.897      0.87287287 0.88588589 0.89289289 0.88188188]\n",
            "Mean Accuracy: 0.8861067067067067\n",
            "\n",
            "k-Nearest Neighbors Cross-Validation Scores:\n",
            "[0.731      0.69069069 0.70870871 0.70870871 0.71071071]\n",
            "Mean Accuracy: 0.7099637637637638\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Multinomial Naive Bayes Classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_scores = cross_val_score(nb_classifier, chisq_8k, y, cv=5)\n",
        "\n",
        "print(\"Multinomial Naive Bayes Cross-Validation Scores:\")\n",
        "print(nb_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(nb_scores))\n",
        "\n",
        "# k-Nearest Neighbors Classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_scores = cross_val_score(knn_classifier, chisq_5k, y, cv=5)\n",
        "\n",
        "print(\"\\nk-Nearest Neighbors Cross-Validation Scores:\")\n",
        "print(knn_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(knn_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import cross_val_score, KFold\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# # Load your data\n",
        "# # Assuming X and y are your features and target variables\n",
        "\n",
        "# # Initialize models\n",
        "# svm_model = SVC(kernel='linear')  # Linear SVM\n",
        "# logistic_model = LogisticRegression()\n",
        "\n",
        "# # Initialize KFold cross-validation\n",
        "# kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# # Perform 5-fold cross-validation for SVM\n",
        "# svm_scores = cross_val_score(svm_model, chisq_5k, y, cv=kfold)\n",
        "\n",
        "# # Perform 5-fold cross-validation for Logistic Regression\n",
        "# logistic_scores = cross_val_score(logistic_model, chisq_8k, y, cv=kfold)\n",
        "\n",
        "# # Display the cross-validation scores\n",
        "# print(\"SVM Cross-validation scores:\", svm_scores)\n",
        "# print(\"Logistic Regression Cross-validation scores:\", logistic_scores)\n",
        "\n",
        "# # Optionally, you can calculate mean and standard deviation of the scores\n",
        "# print(\"SVM Mean Accuracy:\", np.mean(svm_scores))\n",
        "# print(\"SVM Standard Deviation of Accuracy:\", np.std(svm_scores))\n",
        "# print(\"Logistic Regression Mean Accuracy:\", np.mean(logistic_scores))\n",
        "# print(\"Logistic Regression Standard Deviation of Accuracy:\", np.std(logistic_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "125/125 [==============================] - 2s 11ms/step - loss: 0.3699 - accuracy: 0.8226\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0278 - accuracy: 0.9915\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 7.5387e-04 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 4.0712e-04 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 2.5781e-04 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 1.8200e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 1.3513e-04 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 1.0455e-04 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 8.3019e-05 - accuracy: 1.0000\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Neural Network Accuracy on Test Set: 0.933\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Assuming chisq_8k has features and y is the output\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(chisq_8k, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Neural Network Accuracy on Test Set:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.3344 - accuracy: 0.8459 - val_loss: 0.1968 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.2003 - val_accuracy: 0.9250\n",
            "Epoch 3/50\n",
            "113/113 [==============================] - 1s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9275\n",
            "Epoch 4/50\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 6.0237e-04 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9225\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Neural Network Accuracy on Test Set: 0.93\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming chisq_8k has features and y is the output\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(chisq_8k, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train, \n",
        "    epochs=50, batch_size=32, \n",
        "    validation_split=0.1,  # Using a portion of training set for validation\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Neural Network Accuracy on Test Set:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
