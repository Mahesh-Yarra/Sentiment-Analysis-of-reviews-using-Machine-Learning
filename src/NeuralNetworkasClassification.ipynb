{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8UEb9OHI4gNS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from langdetect import detect\n",
        "from urllib.parse import urlsplit\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OutputSentiment\n",
              "positive    2519\n",
              "negative    2481\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"../Dataset/IMDB Dataset.csv\")\n",
        "df.head()\n",
        "df = df.rename(columns={'review': 'OriginalReviews'})\n",
        "df = df.rename(columns={'sentiment': 'OutputSentiment'})\n",
        "df_subset = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
        "df_subset.head()\n",
        "df_subset['OutputSentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really liked this Summerslam due to the look...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not many television shows appeal to quite as m...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film quickly gets to a major chase scene w...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jane Austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Expectations were somewhat high for me when I ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>One of eastwood's best movies after he had sep...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>My blurred childhood memories have kept the ec...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>I love Zombie-Movies and I love amateur-produc...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Chan is in New York and he gets involved with ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>My wife and I both thought this film a watered...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment\n",
              "0     I really liked this Summerslam due to the look...        positive\n",
              "1     Not many television shows appeal to quite as m...        positive\n",
              "2     The film quickly gets to a major chase scene w...        negative\n",
              "3     Jane Austen would definitely approve of this o...        positive\n",
              "4     Expectations were somewhat high for me when I ...        negative\n",
              "...                                                 ...             ...\n",
              "4995  One of eastwood's best movies after he had sep...        positive\n",
              "4996  My blurred childhood memories have kept the ec...        negative\n",
              "4997  I love Zombie-Movies and I love amateur-produc...        negative\n",
              "4998  Chan is in New York and he gets involved with ...        positive\n",
              "4999  My wife and I both thought this film a watered...        negative\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                        OriginalReviews OutputSentiment  \\\n",
            "0     i really liked this summerslam due to the look...        positive   \n",
            "1     not many television shows appeal to quite as m...        positive   \n",
            "2     the film quickly gets to a major chase scene w...        negative   \n",
            "3     jane austen would definitely approve of this o...        positive   \n",
            "4     expectations were somewhat high for me when i ...        negative   \n",
            "...                                                 ...             ...   \n",
            "4995  one of eastwood's best movies after he had sep...        positive   \n",
            "4996  my blurred childhood memories have kept the ec...        negative   \n",
            "4997  i love zombie-movies and i love amateur-produc...        negative   \n",
            "4998  chan is in new york and he gets involved with ...        positive   \n",
            "4999  my wife and i both thought this film a watered...        negative   \n",
            "\n",
            "      PunctuationCount  \n",
            "0                   23  \n",
            "1                   72  \n",
            "2                   22  \n",
            "3                   50  \n",
            "4                   86  \n",
            "...                ...  \n",
            "4995                 4  \n",
            "4996                52  \n",
            "4997                51  \n",
            "4998                27  \n",
            "4999                43  \n",
            "\n",
            "[5000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#lowercase\n",
        "df_subset[\"OriginalReviews\"]=df_subset[\"OriginalReviews\"].apply(lambda x:x.lower())\n",
        "\n",
        "# Function to remove punctuation from text\n",
        "def remove_punctuation_from_text(text):\n",
        "    punctuation_to_remove = string.punctuation\n",
        "    translator = str.maketrans(\"\", \"\", punctuation_to_remove)\n",
        "    return text.translate(translator)\n",
        "\n",
        "# Remove punctuation and count punctuation in each input text\n",
        "def count_punctuation(text):\n",
        "    text_without_punctuation = remove_punctuation_from_text(text)\n",
        "    punctuation_count = len(text) - len(text_without_punctuation)\n",
        "    return punctuation_count\n",
        "\n",
        "# Apply the function to count punctuation and add as a new column\n",
        "df_subset['PunctuationCount'] = df_subset['OriginalReviews'].apply(count_punctuation)\n",
        "\n",
        "# Remove numbers from the 'OriginalReviewss' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].str.replace('\\d+', '')\n",
        "\n",
        "print(df_subset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>PunctuationCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really liked this summerslam due to the look...</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not many television shows appeal to quite as m...</td>\n",
              "      <td>positive</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film quickly gets to a major chase scene w...</td>\n",
              "      <td>negative</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>expectations were somewhat high for me when i ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>one of eastwood's best movies after he had sep...</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>my blurred childhood memories have kept the ec...</td>\n",
              "      <td>negative</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>i love zombie-movies and i love amateur-produc...</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>chan is in new york and he gets involved with ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>my wife and i both thought this film a watered...</td>\n",
              "      <td>negative</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment  \\\n",
              "0     i really liked this summerslam due to the look...        positive   \n",
              "1     not many television shows appeal to quite as m...        positive   \n",
              "2     the film quickly gets to a major chase scene w...        negative   \n",
              "3     jane austen would definitely approve of this o...        positive   \n",
              "4     expectations were somewhat high for me when i ...        negative   \n",
              "...                                                 ...             ...   \n",
              "4995  one of eastwood's best movies after he had sep...        positive   \n",
              "4996  my blurred childhood memories have kept the ec...        negative   \n",
              "4997  i love zombie-movies and i love amateur-produc...        negative   \n",
              "4998  chan is in new york and he gets involved with ...        positive   \n",
              "4999  my wife and i both thought this film a watered...        negative   \n",
              "\n",
              "      PunctuationCount  \n",
              "0                   23  \n",
              "1                   72  \n",
              "2                   22  \n",
              "3                   50  \n",
              "4                   86  \n",
              "...                ...  \n",
              "4995                 4  \n",
              "4996                52  \n",
              "4997                51  \n",
              "4998                27  \n",
              "4999                43  \n",
              "\n",
              "[5000 rows x 3 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# NLTK stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stopwords from text and count them\n",
        "def remove_stopwords_and_count(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    stopwords_count = len(tokens) - len(filtered_tokens)\n",
        "    return stopwords_count\n",
        "\n",
        "# Apply the function to remove stopwords and count them, then add as a new column\n",
        "df_subset['StopwordsCount'] = df_subset['OriginalReviews'].apply(remove_stopwords_and_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>PunctuationCount</th>\n",
              "      <th>StopwordsCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really liked this summerslam due to the look...</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not many television shows appeal to quite as m...</td>\n",
              "      <td>positive</td>\n",
              "      <td>72</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film quickly gets to a major chase scene w...</td>\n",
              "      <td>negative</td>\n",
              "      <td>22</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>50</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>expectations were somewhat high for me when i ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>86</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>one of eastwood's best movies after he had sep...</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>my blurred childhood memories have kept the ec...</td>\n",
              "      <td>negative</td>\n",
              "      <td>52</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>i love zombie-movies and i love amateur-produc...</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>chan is in new york and he gets involved with ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>my wife and i both thought this film a watered...</td>\n",
              "      <td>negative</td>\n",
              "      <td>43</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment  \\\n",
              "0     i really liked this summerslam due to the look...        positive   \n",
              "1     not many television shows appeal to quite as m...        positive   \n",
              "2     the film quickly gets to a major chase scene w...        negative   \n",
              "3     jane austen would definitely approve of this o...        positive   \n",
              "4     expectations were somewhat high for me when i ...        negative   \n",
              "...                                                 ...             ...   \n",
              "4995  one of eastwood's best movies after he had sep...        positive   \n",
              "4996  my blurred childhood memories have kept the ec...        negative   \n",
              "4997  i love zombie-movies and i love amateur-produc...        negative   \n",
              "4998  chan is in new york and he gets involved with ...        positive   \n",
              "4999  my wife and i both thought this film a watered...        negative   \n",
              "\n",
              "      PunctuationCount  StopwordsCount  \n",
              "0                   23              84  \n",
              "1                   72             162  \n",
              "2                   22              54  \n",
              "3                   50              39  \n",
              "4                   86             166  \n",
              "...                ...             ...  \n",
              "4995                 4              24  \n",
              "4996                52              59  \n",
              "4997                51              56  \n",
              "4998                27              88  \n",
              "4999                43              83  \n",
              "\n",
              "[5000 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_urls(text):\n",
        "    # Define a regular expression pattern to match URLs\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "\n",
        "    # Find all matches in the text\n",
        "    urls = re.findall(url_pattern, text)\n",
        "\n",
        "    # Remove URLs from the text\n",
        "    text_without_urls = re.sub(url_pattern, '', text)\n",
        "\n",
        "    return text_without_urls\n",
        "\n",
        "# Example usage\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdidd\\AppData\\Local\\Temp\\ipykernel_7020\\3731208440.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, 'html.parser')\n"
          ]
        }
      ],
      "source": [
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    return soup.get_text()\n",
        "\n",
        "df_subset[\"OriginalReviews\"] = df_subset[\"OriginalReviews\"].apply(remove_html_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_extra_whitespaces(text):\n",
        "    # Use regular expression to replace multiple whitespaces with a single space\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_extra_whitespaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_non_english(text):\n",
        "    try:\n",
        "        return detect(text) == 'en'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Create a boolean mask for non-English OriginalReviewss\n",
        "mask = df_subset['OriginalReviews'].apply(filter_non_english)\n",
        "\n",
        "# Create a new DataFrame containing only English OriginalReviewss\n",
        "df_subset = df_subset[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to get the part of speech for WordNet lemmatizer\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # Default to noun if the part of speech is not found\n",
        "\n",
        "# Function to lemmatize a text\n",
        "def lemmatize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply lemmatization to the 'text' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "def count_word_types(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    \n",
        "    adj_count = 0\n",
        "    adv_count = 0\n",
        "    temporal_count = 0\n",
        "    \n",
        "    for word, tag in tagged_tokens:\n",
        "        if tag.startswith('JJ'):  # Adjective\n",
        "            adj_count += 1\n",
        "        elif tag.startswith('RB'):  # Adverb\n",
        "            adv_count += 1\n",
        "            \n",
        "    return {'AdjectiveCount': adj_count, 'AdverbCount': adv_count}\n",
        "\n",
        "# Apply the function to count word types and add as new columns\n",
        "df_counts = df_subset['OriginalReviews'].apply(count_word_types).apply(pd.Series)\n",
        "\n",
        "# Concatenate the counts DataFrame with the original DataFrame\n",
        "df_subset = pd.concat([df_subset, df_counts], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>PunctuationCount</th>\n",
              "      <th>StopwordsCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>TemporalWordCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really like this summerslam due to the look ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not many television show appeal to quite a man...</td>\n",
              "      <td>positive</td>\n",
              "      <td>72</td>\n",
              "      <td>162</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film quickly get to a major chase scene wi...</td>\n",
              "      <td>negative</td>\n",
              "      <td>22</td>\n",
              "      <td>54</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>50</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>expectation be somewhat high for me when i go ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>86</td>\n",
              "      <td>166</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>one of eastwoods best movie after he have sepa...</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>my blur childhood memory have keep the echo of...</td>\n",
              "      <td>negative</td>\n",
              "      <td>52</td>\n",
              "      <td>59</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>i love zombiemovies and i love amateurproducti...</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>chan be in new york and he get involve with an...</td>\n",
              "      <td>positive</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>my wife and i both thought this film a watered...</td>\n",
              "      <td>negative</td>\n",
              "      <td>43</td>\n",
              "      <td>83</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment  \\\n",
              "0     i really like this summerslam due to the look ...        positive   \n",
              "1     not many television show appeal to quite a man...        positive   \n",
              "2     the film quickly get to a major chase scene wi...        negative   \n",
              "3     jane austen would definitely approve of this o...        positive   \n",
              "4     expectation be somewhat high for me when i go ...        negative   \n",
              "...                                                 ...             ...   \n",
              "4995  one of eastwoods best movie after he have sepa...        positive   \n",
              "4996  my blur childhood memory have keep the echo of...        negative   \n",
              "4997  i love zombiemovies and i love amateurproducti...        negative   \n",
              "4998  chan be in new york and he get involve with an...        positive   \n",
              "4999  my wife and i both thought this film a watered...        negative   \n",
              "\n",
              "      PunctuationCount  StopwordsCount  AdjectiveCount  AdverbCount  \\\n",
              "0                   23              84              22           14   \n",
              "1                   72             162              39           20   \n",
              "2                   22              54               8            8   \n",
              "3                   50              39              13           13   \n",
              "4                   86             166              33           14   \n",
              "...                ...             ...             ...          ...   \n",
              "4995                 4              24               4            2   \n",
              "4996                52              59              19            7   \n",
              "4997                51              56              12           12   \n",
              "4998                27              88              15           17   \n",
              "4999                43              83              17            8   \n",
              "\n",
              "      TemporalWordCount  AdjectiveCount  AdverbCount  \n",
              "0                     0              22           14  \n",
              "1                     0              39           20  \n",
              "2                     0               8            8  \n",
              "3                     0              13           13  \n",
              "4                     0              33           14  \n",
              "...                 ...             ...          ...  \n",
              "4995                  0               4            2  \n",
              "4996                  0              19            7  \n",
              "4997                  0              12           12  \n",
              "4998                  0              15           17  \n",
              "4999                  0              17            8  \n",
              "\n",
              "[5000 rows x 9 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_subset.to_csv(\"../csv/Preprocessed_data.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction Using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[95], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m X_lda \u001b[38;5;241m=\u001b[39m lda_pipeline\u001b[38;5;241m.\u001b[39mfit_transform(df_subset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginalReviews\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Concatenate the existing DataFrame with the new features DataFrames\u001b[39;00m\n\u001b[0;32m     26\u001b[0m df_lda \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m     27\u001b[0m     df_subset,\n\u001b[1;32m---> 28\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(X_tfidf\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39m\u001b[43mtfidf_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcountvectorizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m()),\n\u001b[0;32m     29\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(X_lda, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_topics)])\n\u001b[0;32m     30\u001b[0m ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m df_lda\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../csv/separate_features_df.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Define the number of topics for LDA\n",
        "num_topics = 150  # You can adjust this number based on your requirements\n",
        "\n",
        "# Create a pipeline for TF-IDF features\n",
        "tfidf_pipeline = make_pipeline(\n",
        "    CountVectorizer(),  # CountVectorizer converts text to a matrix of token counts\n",
        "    TfidfTransformer()  # TF-IDF transformation\n",
        ")\n",
        "\n",
        "# Create a pipeline for LDA\n",
        "lda_pipeline = make_pipeline(\n",
        "    CountVectorizer(),  # CountVectorizer converts text to a matrix of token counts\n",
        "    TfidfTransformer(),  # TF-IDF transformation\n",
        "    LatentDirichletAllocation(n_components=num_topics, random_state=42)  # LDA for topic modeling\n",
        ")\n",
        "\n",
        "# Fit and transform data separately for TF-IDF and LDA\n",
        "X_tfidf = tfidf_pipeline.fit_transform(df_subset['OriginalReviews'])\n",
        "X_lda = lda_pipeline.fit_transform(df_subset['OriginalReviews'])\n",
        "\n",
        "# Get feature names from the CountVectorizer in the TF-IDF pipeline\n",
        "tfidf_feature_names = tfidf_pipeline.named_steps['countvectorizer'].get_feature_names()\n",
        "\n",
        "# Concatenate the existing DataFrame with the new features DataFrames\n",
        "df_lda = pd.concat([\n",
        "    df_subset,\n",
        "    pd.DataFrame(X_tfidf.toarray(), columns=tfidf_feature_names),\n",
        "    pd.DataFrame(X_lda, columns=[f\"Topic_{i}\" for i in range(num_topics)])\n",
        "], axis=1)\n",
        "\n",
        "df_lda.to_csv(\"../csv/separate_features_df.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>PunctuationCount</th>\n",
              "      <th>StopwordsCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>TemporalWordCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really like this summerslam due to the look ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>(0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not many television show appeal to quite a man...</td>\n",
              "      <td>positive</td>\n",
              "      <td>72</td>\n",
              "      <td>162</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>(0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film quickly get to a major chase scene wi...</td>\n",
              "      <td>negative</td>\n",
              "      <td>22</td>\n",
              "      <td>54</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>(0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>50</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>(0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>expectation be somewhat high for me when i go ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>86</td>\n",
              "      <td>166</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>(0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>one of eastwoods best movie after he have sepa...</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>(0, 1607)\\t0.11598554105252347\\n  (0, 2407)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>my blur childhood memory have keep the echo of...</td>\n",
              "      <td>negative</td>\n",
              "      <td>52</td>\n",
              "      <td>59</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>(0, 712)\\t0.10573088796429253\\n  (0, 1166)\\t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>i love zombiemovies and i love amateurproducti...</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>(0, 1282)\\t0.05867925161486874\\n  (0, 1607)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>chan be in new york and he get involve with an...</td>\n",
              "      <td>positive</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>(0, 991)\\t0.03464006112331686\\n  (0, 1784)\\t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>my wife and i both thought this film a watered...</td>\n",
              "      <td>negative</td>\n",
              "      <td>43</td>\n",
              "      <td>83</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>(0, 1632)\\t0.055070827350439944\\n  (0, 2000)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment  \\\n",
              "0     i really like this summerslam due to the look ...        positive   \n",
              "1     not many television show appeal to quite a man...        positive   \n",
              "2     the film quickly get to a major chase scene wi...        negative   \n",
              "3     jane austen would definitely approve of this o...        positive   \n",
              "4     expectation be somewhat high for me when i go ...        negative   \n",
              "...                                                 ...             ...   \n",
              "4995  one of eastwoods best movie after he have sepa...        positive   \n",
              "4996  my blur childhood memory have keep the echo of...        negative   \n",
              "4997  i love zombiemovies and i love amateurproducti...        negative   \n",
              "4998  chan be in new york and he get involve with an...        positive   \n",
              "4999  my wife and i both thought this film a watered...        negative   \n",
              "\n",
              "      PunctuationCount  StopwordsCount  AdjectiveCount  AdverbCount  \\\n",
              "0                   23              84              22           14   \n",
              "1                   72             162              39           20   \n",
              "2                   22              54               8            8   \n",
              "3                   50              39              13           13   \n",
              "4                   86             166              33           14   \n",
              "...                ...             ...             ...          ...   \n",
              "4995                 4              24               4            2   \n",
              "4996                52              59              19            7   \n",
              "4997                51              56              12           12   \n",
              "4998                27              88              15           17   \n",
              "4999                43              83              17            8   \n",
              "\n",
              "      TemporalWordCount  AdjectiveCount  AdverbCount  \\\n",
              "0                     0              22           14   \n",
              "1                     0              39           20   \n",
              "2                     0               8            8   \n",
              "3                     0              13           13   \n",
              "4                     0              33           14   \n",
              "...                 ...             ...          ...   \n",
              "4995                  0               4            2   \n",
              "4996                  0              19            7   \n",
              "4997                  0              12           12   \n",
              "4998                  0              15           17   \n",
              "4999                  0              17            8   \n",
              "\n",
              "                                                      0  \n",
              "0       (0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...  \n",
              "1       (0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...  \n",
              "2       (0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...  \n",
              "3       (0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...  \n",
              "4       (0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...  \n",
              "...                                                 ...  \n",
              "4995    (0, 1607)\\t0.11598554105252347\\n  (0, 2407)\\...  \n",
              "4996    (0, 712)\\t0.10573088796429253\\n  (0, 1166)\\t...  \n",
              "4997    (0, 1282)\\t0.05867925161486874\\n  (0, 1607)\\...  \n",
              "4998    (0, 991)\\t0.03464006112331686\\n  (0, 1784)\\t...  \n",
              "4999    (0, 1632)\\t0.055070827350439944\\n  (0, 2000)...  \n",
              "\n",
              "[5000 rows x 10 columns]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CONNOTATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download the VADER lexicon (run this once)\n",
        "nltk.download('vader_lexicon')\n",
        "delimiter = '\\t'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "positive = pd.read_csv(r'..\\Connotations\\positive-words.txt', sep=delimiter, names=['words'])\n",
        "negative = pd.read_csv(r'..\\Connotations\\negative-words.txt', sep=delimiter, names=['words'])\n",
        "connotations = pd.read_csv(r\"..\\Connotations\\connotations.csv\")\n",
        "\n",
        "word_emotion_map = dict(zip(connotations['word'], connotations['emotion']))\n",
        "\n",
        "# Assuming word_emotion_map and update_counts functions are defined\n",
        "\n",
        "def update_counts(review):\n",
        "    positive_count = sum(1 for word in review.split() if word in word_emotion_map and word_emotion_map[word] == 'positive')\n",
        "    negative_count = sum(1 for word in review.split() if word in word_emotion_map and word_emotion_map[word] == 'negative')\n",
        "    return positive_count, negative_count\n",
        "\n",
        "# Apply the update_counts function row-wise and split the returned tuple into separate columns\n",
        "df_lda[['Positive_Connotation_Count', 'Negative_Connotation_Count']] = df_lda.apply(lambda row: pd.Series(update_counts(row['OriginalReviews'])), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load positive and negative words from files\n",
        "positive_words_df = pd.read_csv(r'..\\Connotations\\positive-words.txt', header=None, names=['words'])\n",
        "negative_words_df = pd.read_csv(r'..\\Connotations\\negative-words.txt', header=None, names=['words'])\n",
        "\n",
        "# Convert DataFrame columns to sets\n",
        "positive_words = set(positive_words_df['words'].tolist())\n",
        "negative_words = set(negative_words_df['words'].tolist())\n",
        "\n",
        "# Assuming 'tfidf_df_13k' is your DataFrame\n",
        "# Define a function to update counts based on positive and negative words\n",
        "def update_word_counts(review):\n",
        "    positive_count = sum(1 for word in review.split() if word in positive_words)\n",
        "    negative_count = sum(1 for word in review.split() if word in negative_words)\n",
        "    return positive_count, negative_count\n",
        "\n",
        "# Apply the function to the 'OriginalReviews' column and unpack the result into two new columns\n",
        "df_lda[['Positive_Word_Count', 'Negative_Word_Count']] = df_lda.apply(lambda row: pd.Series(update_word_counts(row['OriginalReviews'])), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "# Use VADER for sentiment analysis\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(review):\n",
        "    scores = sid.polarity_scores(review)\n",
        "    return scores['pos'] *100, scores['neg'] * 100\n",
        "\n",
        "# Apply the function to the 'OriginalReviews' column and unpack the result into two new columns\n",
        "df_lda[['Positive_VADER_Count', 'Negative_VADER_Count']] = df_lda.apply(lambda row: pd.Series(vader_sentiment(row['OriginalReviews'])), axis=1)\n",
        "\n",
        "df_lda.to_csv(\"../csv/df_lda_connotations_vader.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>PunctuationCount</th>\n",
              "      <th>StopwordsCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>TemporalWordCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>0</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really like this summerslam due to the look ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>(0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...</td>\n",
              "      <td>73</td>\n",
              "      <td>44</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>12.6</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not many television show appeal to quite a man...</td>\n",
              "      <td>positive</td>\n",
              "      <td>72</td>\n",
              "      <td>162</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>(0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...</td>\n",
              "      <td>105</td>\n",
              "      <td>96</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>13.4</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film quickly get to a major chase scene wi...</td>\n",
              "      <td>negative</td>\n",
              "      <td>22</td>\n",
              "      <td>54</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>(0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...</td>\n",
              "      <td>28</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>15.3</td>\n",
              "      <td>3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>50</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>(0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>expectation be somewhat high for me when i go ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>86</td>\n",
              "      <td>166</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>(0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...</td>\n",
              "      <td>99</td>\n",
              "      <td>70</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>9.3</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>one of eastwoods best movie after he have sepa...</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>(0, 1607)\\t0.11598554105252347\\n  (0, 2407)\\...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>19.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>my blur childhood memory have keep the echo of...</td>\n",
              "      <td>negative</td>\n",
              "      <td>52</td>\n",
              "      <td>59</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>(0, 712)\\t0.10573088796429253\\n  (0, 1166)\\t...</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>i love zombiemovies and i love amateurproducti...</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>(0, 1282)\\t0.05867925161486874\\n  (0, 1607)\\...</td>\n",
              "      <td>41</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>19.4</td>\n",
              "      <td>5.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>chan be in new york and he get involve with an...</td>\n",
              "      <td>positive</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>(0, 991)\\t0.03464006112331686\\n  (0, 1784)\\t...</td>\n",
              "      <td>40</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>20.4</td>\n",
              "      <td>16.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>my wife and i both thought this film a watered...</td>\n",
              "      <td>negative</td>\n",
              "      <td>43</td>\n",
              "      <td>83</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>(0, 1632)\\t0.055070827350439944\\n  (0, 2000)...</td>\n",
              "      <td>42</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>7.5</td>\n",
              "      <td>9.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment  \\\n",
              "0     i really like this summerslam due to the look ...        positive   \n",
              "1     not many television show appeal to quite a man...        positive   \n",
              "2     the film quickly get to a major chase scene wi...        negative   \n",
              "3     jane austen would definitely approve of this o...        positive   \n",
              "4     expectation be somewhat high for me when i go ...        negative   \n",
              "...                                                 ...             ...   \n",
              "4995  one of eastwoods best movie after he have sepa...        positive   \n",
              "4996  my blur childhood memory have keep the echo of...        negative   \n",
              "4997  i love zombiemovies and i love amateurproducti...        negative   \n",
              "4998  chan be in new york and he get involve with an...        positive   \n",
              "4999  my wife and i both thought this film a watered...        negative   \n",
              "\n",
              "      PunctuationCount  StopwordsCount  AdjectiveCount  AdverbCount  \\\n",
              "0                   23              84              22           14   \n",
              "1                   72             162              39           20   \n",
              "2                   22              54               8            8   \n",
              "3                   50              39              13           13   \n",
              "4                   86             166              33           14   \n",
              "...                ...             ...             ...          ...   \n",
              "4995                 4              24               4            2   \n",
              "4996                52              59              19            7   \n",
              "4997                51              56              12           12   \n",
              "4998                27              88              15           17   \n",
              "4999                43              83              17            8   \n",
              "\n",
              "      TemporalWordCount  AdjectiveCount  AdverbCount  \\\n",
              "0                     0              22           14   \n",
              "1                     0              39           20   \n",
              "2                     0               8            8   \n",
              "3                     0              13           13   \n",
              "4                     0              33           14   \n",
              "...                 ...             ...          ...   \n",
              "4995                  0               4            2   \n",
              "4996                  0              19            7   \n",
              "4997                  0              12           12   \n",
              "4998                  0              15           17   \n",
              "4999                  0              17            8   \n",
              "\n",
              "                                                      0  \\\n",
              "0       (0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...   \n",
              "1       (0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...   \n",
              "2       (0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...   \n",
              "3       (0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...   \n",
              "4       (0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...   \n",
              "...                                                 ...   \n",
              "4995    (0, 1607)\\t0.11598554105252347\\n  (0, 2407)\\...   \n",
              "4996    (0, 712)\\t0.10573088796429253\\n  (0, 1166)\\t...   \n",
              "4997    (0, 1282)\\t0.05867925161486874\\n  (0, 1607)\\...   \n",
              "4998    (0, 991)\\t0.03464006112331686\\n  (0, 1784)\\t...   \n",
              "4999    (0, 1632)\\t0.055070827350439944\\n  (0, 2000)...   \n",
              "\n",
              "      Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0                             73                          44   \n",
              "1                            105                          96   \n",
              "2                             28                          31   \n",
              "3                             30                          24   \n",
              "4                             99                          70   \n",
              "...                          ...                         ...   \n",
              "4995                           9                          11   \n",
              "4996                          40                          24   \n",
              "4997                          41                          26   \n",
              "4998                          40                          59   \n",
              "4999                          42                          49   \n",
              "\n",
              "      Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                       7                    9                  12.6   \n",
              "1                      14                    6                  13.4   \n",
              "2                       4                    4                  15.3   \n",
              "3                       8                    5                  21.0   \n",
              "4                       8                   10                   9.3   \n",
              "...                   ...                  ...                   ...   \n",
              "4995                    3                    0                  19.7   \n",
              "4996                    3                    4                  11.0   \n",
              "4997                   11                    3                  19.4   \n",
              "4998                    8                    5                  20.4   \n",
              "4999                    5                    5                   7.5   \n",
              "\n",
              "      Negative_VADER_Count  \n",
              "0                     10.3  \n",
              "1                      1.3  \n",
              "2                      3.7  \n",
              "3                     12.1  \n",
              "4                      9.5  \n",
              "...                    ...  \n",
              "4995                   0.0  \n",
              "4996                  10.7  \n",
              "4997                   5.6  \n",
              "4998                  16.9  \n",
              "4999                   9.6  \n",
              "\n",
              "[5000 rows x 16 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# text = tfidf_df_13k.iloc[4993]['OriginalReviews']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tfidf_df_13k = pd.read_csv(\"../csv/tfidf_df_13k.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tfidf_df_13k_connotations = pd.read_csv('../csv/tfidf_df_13k_connotations_vader.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "1PSHjJbnJcoJ"
      },
      "outputs": [],
      "source": [
        "# tfidf_df_13k_connotations = df_lda.drop('Unnamed: 0',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lda_connotations = df_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>PunctuationCount</th>\n",
              "      <th>StopwordsCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>TemporalWordCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>0</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really like this summerslam due to the look ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>(0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...</td>\n",
              "      <td>73</td>\n",
              "      <td>44</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>12.6</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not many television show appeal to quite a man...</td>\n",
              "      <td>positive</td>\n",
              "      <td>72</td>\n",
              "      <td>162</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>(0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...</td>\n",
              "      <td>105</td>\n",
              "      <td>96</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>13.4</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film quickly get to a major chase scene wi...</td>\n",
              "      <td>negative</td>\n",
              "      <td>22</td>\n",
              "      <td>54</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>(0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...</td>\n",
              "      <td>28</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>15.3</td>\n",
              "      <td>3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>50</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>(0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>expectation be somewhat high for me when i go ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>86</td>\n",
              "      <td>166</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>(0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...</td>\n",
              "      <td>99</td>\n",
              "      <td>70</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>9.3</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>one of eastwoods best movie after he have sepa...</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>(0, 1607)\\t0.11598554105252347\\n  (0, 2407)\\...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>19.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>my blur childhood memory have keep the echo of...</td>\n",
              "      <td>negative</td>\n",
              "      <td>52</td>\n",
              "      <td>59</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>(0, 712)\\t0.10573088796429253\\n  (0, 1166)\\t...</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>i love zombiemovies and i love amateurproducti...</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>(0, 1282)\\t0.05867925161486874\\n  (0, 1607)\\...</td>\n",
              "      <td>41</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>19.4</td>\n",
              "      <td>5.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>chan be in new york and he get involve with an...</td>\n",
              "      <td>positive</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>(0, 991)\\t0.03464006112331686\\n  (0, 1784)\\t...</td>\n",
              "      <td>40</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>20.4</td>\n",
              "      <td>16.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>my wife and i both thought this film a watered...</td>\n",
              "      <td>negative</td>\n",
              "      <td>43</td>\n",
              "      <td>83</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>(0, 1632)\\t0.055070827350439944\\n  (0, 2000)...</td>\n",
              "      <td>42</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>7.5</td>\n",
              "      <td>9.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment  \\\n",
              "0     i really like this summerslam due to the look ...        positive   \n",
              "1     not many television show appeal to quite a man...        positive   \n",
              "2     the film quickly get to a major chase scene wi...        negative   \n",
              "3     jane austen would definitely approve of this o...        positive   \n",
              "4     expectation be somewhat high for me when i go ...        negative   \n",
              "...                                                 ...             ...   \n",
              "4995  one of eastwoods best movie after he have sepa...        positive   \n",
              "4996  my blur childhood memory have keep the echo of...        negative   \n",
              "4997  i love zombiemovies and i love amateurproducti...        negative   \n",
              "4998  chan be in new york and he get involve with an...        positive   \n",
              "4999  my wife and i both thought this film a watered...        negative   \n",
              "\n",
              "      PunctuationCount  StopwordsCount  AdjectiveCount  AdverbCount  \\\n",
              "0                   23              84              22           14   \n",
              "1                   72             162              39           20   \n",
              "2                   22              54               8            8   \n",
              "3                   50              39              13           13   \n",
              "4                   86             166              33           14   \n",
              "...                ...             ...             ...          ...   \n",
              "4995                 4              24               4            2   \n",
              "4996                52              59              19            7   \n",
              "4997                51              56              12           12   \n",
              "4998                27              88              15           17   \n",
              "4999                43              83              17            8   \n",
              "\n",
              "      TemporalWordCount  AdjectiveCount  AdverbCount  \\\n",
              "0                     0              22           14   \n",
              "1                     0              39           20   \n",
              "2                     0               8            8   \n",
              "3                     0              13           13   \n",
              "4                     0              33           14   \n",
              "...                 ...             ...          ...   \n",
              "4995                  0               4            2   \n",
              "4996                  0              19            7   \n",
              "4997                  0              12           12   \n",
              "4998                  0              15           17   \n",
              "4999                  0              17            8   \n",
              "\n",
              "                                                      0  \\\n",
              "0       (0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...   \n",
              "1       (0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...   \n",
              "2       (0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...   \n",
              "3       (0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...   \n",
              "4       (0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...   \n",
              "...                                                 ...   \n",
              "4995    (0, 1607)\\t0.11598554105252347\\n  (0, 2407)\\...   \n",
              "4996    (0, 712)\\t0.10573088796429253\\n  (0, 1166)\\t...   \n",
              "4997    (0, 1282)\\t0.05867925161486874\\n  (0, 1607)\\...   \n",
              "4998    (0, 991)\\t0.03464006112331686\\n  (0, 1784)\\t...   \n",
              "4999    (0, 1632)\\t0.055070827350439944\\n  (0, 2000)...   \n",
              "\n",
              "      Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0                             73                          44   \n",
              "1                            105                          96   \n",
              "2                             28                          31   \n",
              "3                             30                          24   \n",
              "4                             99                          70   \n",
              "...                          ...                         ...   \n",
              "4995                           9                          11   \n",
              "4996                          40                          24   \n",
              "4997                          41                          26   \n",
              "4998                          40                          59   \n",
              "4999                          42                          49   \n",
              "\n",
              "      Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                       7                    9                  12.6   \n",
              "1                      14                    6                  13.4   \n",
              "2                       4                    4                  15.3   \n",
              "3                       8                    5                  21.0   \n",
              "4                       8                   10                   9.3   \n",
              "...                   ...                  ...                   ...   \n",
              "4995                    3                    0                  19.7   \n",
              "4996                    3                    4                  11.0   \n",
              "4997                   11                    3                  19.4   \n",
              "4998                    8                    5                  20.4   \n",
              "4999                    5                    5                   7.5   \n",
              "\n",
              "      Negative_VADER_Count  \n",
              "0                     10.3  \n",
              "1                      1.3  \n",
              "2                      3.7  \n",
              "3                     12.1  \n",
              "4                      9.5  \n",
              "...                    ...  \n",
              "4995                   0.0  \n",
              "4996                  10.7  \n",
              "4997                   5.6  \n",
              "4998                  16.9  \n",
              "4999                   9.6  \n",
              "\n",
              "[5000 rows x 16 columns]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lda_connotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "uTeIZqyGNoLJ",
        "outputId": "ec0a348c-7c08-45a6-a607-4fe270099f03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>TemporalWordCount</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  OutputSentiment  TemporalWordCount  \\\n",
              "0        positive                  0   \n",
              "1        positive                  0   \n",
              "2        negative                  0   \n",
              "3        positive                  0   \n",
              "4        negative                  0   \n",
              "\n",
              "                                                   0  \n",
              "0    (0, 100)\\t0.09506747668032936\\n  (0, 811)\\t0...  \n",
              "1    (0, 96)\\t0.058933434637839684\\n  (0, 553)\\t0...  \n",
              "2    (0, 1242)\\t0.08513785978361742\\n  (0, 1968)\\...  \n",
              "3    (0, 1088)\\t0.10148153949160933\\n  (0, 2148)\\...  \n",
              "4    (0, 612)\\t0.05950598446226236\\n  (0, 1346)\\t...  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_statistical = df_lda_connotations.drop(columns=['OriginalReviews','AdjectiveCount','AdverbCount','StopwordsCount','PunctuationCount','Positive_Connotation_Count','Negative_Connotation_Count','Positive_Word_Count','Negative_Word_Count','Positive_VADER_Count','Negative_VADER_Count'], axis=1)\n",
        "df_statistical.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "dd-FWJp3N_ug"
      },
      "outputs": [],
      "source": [
        "label = LabelEncoder()\n",
        "df_statistical['OutputSentiment'] = label.fit_transform(df_statistical['OutputSentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CHI SQAURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming required columns are 'StopwordsCount', 'PunctuationCount', etc.\n",
        "required_columns = ['AdverbCount','AdjectiveCount','StopwordsCount', 'PunctuationCount', 'Positive_Connotation_Count',\n",
        "                    'Negative_Connotation_Count', 'Positive_Word_Count', 'Negative_Word_Count',\n",
        "                    'Positive_VADER_Count', 'Negative_VADER_Count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[94], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m df_statistical\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutputSentiment\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m df_statistical[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutputSentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m X_5000 \u001b[38;5;241m=\u001b[39m \u001b[43mchi2_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Get the indices of the selected features\u001b[39;00m\n\u001b[0;32m     10\u001b[0m selected_feature_indices \u001b[38;5;241m=\u001b[39m chi2_selector\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:562\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    560\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 562\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[0;32m    567\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:469\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[1;32m--> 469\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2229\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2227\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[1;32m-> 2229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2236\u001b[0m     )\n\u001b[0;32m   2238\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
          ]
        }
      ],
      "source": [
        "# This will get the top 5000 relavant features out of the sample\n",
        "chi2_selector = SelectKBest(chi2, k=5000)\n",
        "\n",
        "# This will transform the dataset i.e, it will reduce the dimensions by just considering the relavant features only\n",
        "X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "y = df_statistical['OutputSentiment']\n",
        "X_5000 = chi2_selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "\n",
        "chisq_5k = X[selected_feature_names]\n",
        "chisq_5k.head()\n",
        "\n",
        "chisq_5k = pd.concat([chisq_5k,df_lda_connotations[required_columns]],axis=1)\n",
        "chisq_5k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:776: UserWarning: k=8000 is greater than n_features=151. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TemporalWordCount</th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "      <th>Topic_5</th>\n",
              "      <th>Topic_6</th>\n",
              "      <th>Topic_7</th>\n",
              "      <th>Topic_8</th>\n",
              "      <th>...</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>StopwordsCount</th>\n",
              "      <th>PunctuationCount</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.014282</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>84</td>\n",
              "      <td>23</td>\n",
              "      <td>73</td>\n",
              "      <td>44</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>12.6</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.018071</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>39</td>\n",
              "      <td>162</td>\n",
              "      <td>72</td>\n",
              "      <td>105</td>\n",
              "      <td>96</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>13.4</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>15.3</td>\n",
              "      <td>3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>39</td>\n",
              "      <td>50</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>33</td>\n",
              "      <td>166</td>\n",
              "      <td>86</td>\n",
              "      <td>99</td>\n",
              "      <td>70</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>9.3</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 161 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TemporalWordCount   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4  \\\n",
              "0                  0  0.000686  0.000686  0.014282  0.000686  0.000686   \n",
              "1                  0  0.000493  0.000493  0.000493  0.000493  0.000493   \n",
              "2                  0  0.000748  0.000748  0.000748  0.000748  0.000748   \n",
              "3                  0  0.000795  0.000795  0.000795  0.000795  0.000795   \n",
              "4                  0  0.000585  0.000585  0.000585  0.000585  0.000585   \n",
              "\n",
              "    Topic_5   Topic_6   Topic_7   Topic_8  ...  AdverbCount  AdjectiveCount  \\\n",
              "0  0.000686  0.000686  0.000686  0.000686  ...           14              22   \n",
              "1  0.000493  0.000493  0.018071  0.000493  ...           20              39   \n",
              "2  0.000748  0.000748  0.000748  0.000748  ...            8               8   \n",
              "3  0.000795  0.000795  0.000795  0.000795  ...           13              13   \n",
              "4  0.000585  0.000585  0.000585  0.000585  ...           14              33   \n",
              "\n",
              "   StopwordsCount  PunctuationCount  Positive_Connotation_Count  \\\n",
              "0              84                23                          73   \n",
              "1             162                72                         105   \n",
              "2              54                22                          28   \n",
              "3              39                50                          30   \n",
              "4             166                86                          99   \n",
              "\n",
              "   Negative_Connotation_Count  Positive_Word_Count  Negative_Word_Count  \\\n",
              "0                          44                    7                    9   \n",
              "1                          96                   14                    6   \n",
              "2                          31                    4                    4   \n",
              "3                          24                    8                    5   \n",
              "4                          70                    8                   10   \n",
              "\n",
              "   Positive_VADER_Count  Negative_VADER_Count  \n",
              "0                  12.6                  10.3  \n",
              "1                  13.4                   1.3  \n",
              "2                  15.3                   3.7  \n",
              "3                  21.0                  12.1  \n",
              "4                   9.3                   9.5  \n",
              "\n",
              "[5 rows x 161 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This will get the top 8000 relavant features out of the sample\n",
        "chi2_selector = SelectKBest(chi2, k=8000)\n",
        "\n",
        "# This will transform the dataset i.e, it will reduce the dimensions by just considering the relavant features only\n",
        "X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "y = df_statistical['OutputSentiment']\n",
        "X_8000 = chi2_selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "\n",
        "chisq_8k = X[selected_feature_names]\n",
        "chisq_8k.head()\n",
        "\n",
        "chisq_8k = pd.concat([chisq_8k,df_lda_connotations[required_columns]],axis=1)\n",
        "chisq_8k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# # For 5000 relevant features\n",
        "# cor_selector_5k = SelectKBest(f_regression, k=5000)\n",
        "\n",
        "# # Transform the dataset to reduce dimensions by considering only the relevant features\n",
        "# X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "# y = df_statistical['OutputSentiment']\n",
        "# X_5000 = cor_selector_5k.fit_transform(X, y)\n",
        "\n",
        "# # Get the indices of the selected features\n",
        "# selected_feature_indices_5k = cor_selector_5k.get_support(indices=True)\n",
        "\n",
        "# # Get the names of the selected features\n",
        "# selected_feature_names_5k = X.columns[selected_feature_indices_5k]\n",
        "\n",
        "# cor_5k = X[selected_feature_names_5k]\n",
        "# cor_5k.head()\n",
        "\n",
        "# cor_5k = pd.concat([cor_5k, tfidf_df_13k_connotations.iloc[:, -6:]], axis=1)\n",
        "# cor_5k.head()\n",
        "\n",
        "# # For 8000 relevant features\n",
        "# cor_selector_8k = SelectKBest(f_regression, k=8000)\n",
        "\n",
        "# # Transform the dataset to reduce dimensions by considering only the relevant features\n",
        "# X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "# y = df_statistical['OutputSentiment']\n",
        "# X_8000 = cor_selector_8k.fit_transform(X, y)\n",
        "\n",
        "# # Get the indices of the selected features\n",
        "# selected_feature_indices_8k = cor_selector_8k.get_support(indices=True)\n",
        "\n",
        "# # Get the names of the selected features\n",
        "# selected_feature_names_8k = X.columns[selected_feature_indices_8k]\n",
        "\n",
        "# cor_8k = X[selected_feature_names_8k]\n",
        "# cor_8k.head()\n",
        "\n",
        "# cor_8k = pd.concat([cor_8k, tfidf_df_13k_connotations.iloc[:, -6:]], axis=1)\n",
        "# cor_8k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>007</th>\n",
              "      <th>007s</th>\n",
              "      <th>0080</th>\n",
              "      <th>010</th>\n",
              "      <th>1010</th>\n",
              "      <th>1010br</th>\n",
              "      <th>10dirmick</th>\n",
              "      <th>10yearold</th>\n",
              "      <th>1110</th>\n",
              "      <th>112</th>\n",
              "      <th>...</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucco</th>\n",
              "      <th>zunz</th>\n",
              "      <th>zwick</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55</td>\n",
              "      <td>24</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>20.3</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>77</td>\n",
              "      <td>50</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>21.9</td>\n",
              "      <td>2.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>23.1</td>\n",
              "      <td>9.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>18</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>32.4</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>15.9</td>\n",
              "      <td>14.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   007  007s  0080  010  1010  1010br  10dirmick  10yearold  1110  112  ...  \\\n",
              "0  0.0   0.0   0.0  0.0   0.0     0.0        0.0        0.0   0.0  0.0  ...   \n",
              "1  0.0   0.0   0.0  0.0   0.0     0.0        0.0        0.0   0.0  0.0  ...   \n",
              "2  0.0   0.0   0.0  0.0   0.0     0.0        0.0        0.0   0.0  0.0  ...   \n",
              "3  0.0   0.0   0.0  0.0   0.0     0.0        0.0        0.0   0.0  0.0  ...   \n",
              "4  0.0   0.0   0.0  0.0   0.0     0.0        0.0        0.0   0.0  0.0  ...   \n",
              "\n",
              "    zu  zucco  zunz  zwick  Positive_Connotation_Count  \\\n",
              "0  0.0    0.0   0.0    0.0                          55   \n",
              "1  0.0    0.0   0.0    0.0                          77   \n",
              "2  0.0    0.0   0.0    0.0                          20   \n",
              "3  0.0    0.0   0.0    0.0                          22   \n",
              "4  0.0    0.0   0.0    0.0                          69   \n",
              "\n",
              "   Negative_Connotation_Count  Positive_Word_Count  Negative_Word_Count  \\\n",
              "0                          24                    7                    9   \n",
              "1                          50                   14                    6   \n",
              "2                          18                    4                    4   \n",
              "3                          18                    7                    5   \n",
              "4                          42                    8                   10   \n",
              "\n",
              "   Positive_VADER_Count  Negative_VADER_Count  \n",
              "0                  20.3                  12.0  \n",
              "1                  21.9                   2.9  \n",
              "2                  23.1                   9.1  \n",
              "3                  32.4                  10.0  \n",
              "4                  15.9                  14.8  \n",
              "\n",
              "[5 rows x 8006 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "\n",
        "# # For 5000 relevant features using mutual information\n",
        "# info_gain_selector_5k = SelectKBest(mutual_info_regression, k=5000)\n",
        "\n",
        "# # Transform the dataset to reduce dimensions by considering only the relevant features\n",
        "# X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "# y = df_statistical['OutputSentiment']\n",
        "# X_5000 = info_gain_selector_5k.fit_transform(X, y)\n",
        "\n",
        "# # Get the indices of the selected features\n",
        "# selected_feature_indices_5k = info_gain_selector_5k.get_support(indices=True)\n",
        "\n",
        "# # Get the names of the selected features\n",
        "# selected_feature_names_5k = X.columns[selected_feature_indices_5k]\n",
        "\n",
        "# info_gain_5k = X[selected_feature_names_5k]\n",
        "# info_gain_5k.head()\n",
        "\n",
        "# info_gain_5k = pd.concat([info_gain_5k, tfidf_df_13k_connotations.iloc[:, -6:]], axis=1)\n",
        "# info_gain_5k.head()\n",
        "\n",
        "# # For 8000 relevant features using mutual information\n",
        "# info_gain_selector_8k = SelectKBest(mutual_info_regression, k=8000)\n",
        "\n",
        "# # Transform the dataset to reduce dimensions by considering only the relevant features\n",
        "# X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "# y = df_statistical['OutputSentiment']\n",
        "# X_8000 = info_gain_selector_8k.fit_transform(X, y)\n",
        "\n",
        "# # Get the indices of the selected features\n",
        "# selected_feature_indices_8k = info_gain_selector_8k.get_support(indices=True)\n",
        "\n",
        "# # Get the names of the selected features\n",
        "# selected_feature_names_8k = X.columns[selected_feature_indices_8k]\n",
        "\n",
        "# info_gain_8k = X[selected_feature_names_8k]\n",
        "# info_gain_8k.head()\n",
        "\n",
        "# info_gain_8k = pd.concat([info_gain_8k, tfidf_df_13k_connotations.iloc[:, -6:]], axis=1)\n",
        "# info_gain_8k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming chisq_8k is your DataFrame\n",
        "columns_to_normalize = ['Positive_Connotation_Count', 'Negative_Connotation_Count', \n",
        "                         'Positive_Word_Count', 'Negative_Word_Count', \n",
        "                         'Positive_VADER_Count', 'Negative_VADER_Count']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "chisq_8k[columns_to_normalize] = scaler.fit_transform(chisq_8k[columns_to_normalize])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TemporalWordCount</th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "      <th>Topic_5</th>\n",
              "      <th>Topic_6</th>\n",
              "      <th>Topic_7</th>\n",
              "      <th>Topic_8</th>\n",
              "      <th>...</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>AdjectiveCount</th>\n",
              "      <th>StopwordsCount</th>\n",
              "      <th>PunctuationCount</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.014282</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>84</td>\n",
              "      <td>23</td>\n",
              "      <td>0.217666</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.104478</td>\n",
              "      <td>0.134328</td>\n",
              "      <td>0.234201</td>\n",
              "      <td>0.210634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.018071</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>39</td>\n",
              "      <td>162</td>\n",
              "      <td>72</td>\n",
              "      <td>0.318612</td>\n",
              "      <td>0.313333</td>\n",
              "      <td>0.208955</td>\n",
              "      <td>0.089552</td>\n",
              "      <td>0.249071</td>\n",
              "      <td>0.026585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>0.075710</td>\n",
              "      <td>0.096667</td>\n",
              "      <td>0.059701</td>\n",
              "      <td>0.059701</td>\n",
              "      <td>0.284387</td>\n",
              "      <td>0.075665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>39</td>\n",
              "      <td>50</td>\n",
              "      <td>0.082019</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>0.119403</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.390335</td>\n",
              "      <td>0.247444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>33</td>\n",
              "      <td>166</td>\n",
              "      <td>86</td>\n",
              "      <td>0.299685</td>\n",
              "      <td>0.226667</td>\n",
              "      <td>0.119403</td>\n",
              "      <td>0.149254</td>\n",
              "      <td>0.172862</td>\n",
              "      <td>0.194274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>0</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>0.015773</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366171</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>59</td>\n",
              "      <td>52</td>\n",
              "      <td>0.113565</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>0.059701</td>\n",
              "      <td>0.204461</td>\n",
              "      <td>0.218814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>56</td>\n",
              "      <td>51</td>\n",
              "      <td>0.116719</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.164179</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>0.360595</td>\n",
              "      <td>0.114519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.010992</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>88</td>\n",
              "      <td>27</td>\n",
              "      <td>0.113565</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>0.119403</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.379182</td>\n",
              "      <td>0.345603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.024964</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>83</td>\n",
              "      <td>43</td>\n",
              "      <td>0.119874</td>\n",
              "      <td>0.156667</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.139405</td>\n",
              "      <td>0.196319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 161 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      TemporalWordCount   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4  \\\n",
              "0                     0  0.000686  0.000686  0.014282  0.000686  0.000686   \n",
              "1                     0  0.000493  0.000493  0.000493  0.000493  0.000493   \n",
              "2                     0  0.000748  0.000748  0.000748  0.000748  0.000748   \n",
              "3                     0  0.000795  0.000795  0.000795  0.000795  0.000795   \n",
              "4                     0  0.000585  0.000585  0.000585  0.000585  0.000585   \n",
              "...                 ...       ...       ...       ...       ...       ...   \n",
              "4995                  0  0.001097  0.001097  0.001097  0.001097  0.001097   \n",
              "4996                  0  0.000721  0.000721  0.000721  0.000721  0.000721   \n",
              "4997                  0  0.000708  0.000708  0.000708  0.000708  0.000708   \n",
              "4998                  0  0.000680  0.000680  0.000680  0.000680  0.000680   \n",
              "4999                  0  0.000641  0.000641  0.000641  0.000641  0.000641   \n",
              "\n",
              "       Topic_5   Topic_6   Topic_7   Topic_8  ...  AdverbCount  \\\n",
              "0     0.000686  0.000686  0.000686  0.000686  ...           14   \n",
              "1     0.000493  0.000493  0.018071  0.000493  ...           20   \n",
              "2     0.000748  0.000748  0.000748  0.000748  ...            8   \n",
              "3     0.000795  0.000795  0.000795  0.000795  ...           13   \n",
              "4     0.000585  0.000585  0.000585  0.000585  ...           14   \n",
              "...        ...       ...       ...       ...  ...          ...   \n",
              "4995  0.001097  0.001097  0.001097  0.001097  ...            2   \n",
              "4996  0.000721  0.000721  0.000721  0.000721  ...            7   \n",
              "4997  0.000708  0.000708  0.000708  0.000708  ...           12   \n",
              "4998  0.010992  0.000680  0.000680  0.000680  ...           17   \n",
              "4999  0.024964  0.000641  0.000641  0.000641  ...            8   \n",
              "\n",
              "      AdjectiveCount  StopwordsCount  PunctuationCount  \\\n",
              "0                 22              84                23   \n",
              "1                 39             162                72   \n",
              "2                  8              54                22   \n",
              "3                 13              39                50   \n",
              "4                 33             166                86   \n",
              "...              ...             ...               ...   \n",
              "4995               4              24                 4   \n",
              "4996              19              59                52   \n",
              "4997              12              56                51   \n",
              "4998              15              88                27   \n",
              "4999              17              83                43   \n",
              "\n",
              "      Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0                       0.217666                    0.140000   \n",
              "1                       0.318612                    0.313333   \n",
              "2                       0.075710                    0.096667   \n",
              "3                       0.082019                    0.073333   \n",
              "4                       0.299685                    0.226667   \n",
              "...                          ...                         ...   \n",
              "4995                    0.015773                    0.030000   \n",
              "4996                    0.113565                    0.073333   \n",
              "4997                    0.116719                    0.080000   \n",
              "4998                    0.113565                    0.190000   \n",
              "4999                    0.119874                    0.156667   \n",
              "\n",
              "      Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                0.104478             0.134328              0.234201   \n",
              "1                0.208955             0.089552              0.249071   \n",
              "2                0.059701             0.059701              0.284387   \n",
              "3                0.119403             0.074627              0.390335   \n",
              "4                0.119403             0.149254              0.172862   \n",
              "...                   ...                  ...                   ...   \n",
              "4995             0.044776             0.000000              0.366171   \n",
              "4996             0.044776             0.059701              0.204461   \n",
              "4997             0.164179             0.044776              0.360595   \n",
              "4998             0.119403             0.074627              0.379182   \n",
              "4999             0.074627             0.074627              0.139405   \n",
              "\n",
              "      Negative_VADER_Count  \n",
              "0                 0.210634  \n",
              "1                 0.026585  \n",
              "2                 0.075665  \n",
              "3                 0.247444  \n",
              "4                 0.194274  \n",
              "...                    ...  \n",
              "4995              0.000000  \n",
              "4996              0.218814  \n",
              "4997              0.114519  \n",
              "4998              0.345603  \n",
              "4999              0.196319  \n",
              "\n",
              "[5000 rows x 161 columns]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chisq_8k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes Cross-Validation Scores:\n",
            "[0.583 0.608 0.624 0.597 0.616]\n",
            "Mean Accuracy: 0.6056\n",
            "\n",
            "k-Nearest Neighbors Cross-Validation Scores:\n",
            "[0.725 0.716 0.714 0.683 0.715]\n",
            "Mean Accuracy: 0.7106\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Multinomial Naive Bayes Classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_scores = cross_val_score(nb_classifier, chisq_8k, y, cv=5)\n",
        "\n",
        "print(\"Multinomial Naive Bayes Cross-Validation Scores:\")\n",
        "print(nb_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(nb_scores))\n",
        "\n",
        "# k-Nearest Neighbors Classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_scores = cross_val_score(knn_classifier, chisq_5k, y, cv=5)\n",
        "\n",
        "print(\"\\nk-Nearest Neighbors Cross-Validation Scores:\")\n",
        "print(knn_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(knn_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Cross-validation scores: [0.766 0.768 0.756 0.745 0.774]\n",
            "Logistic Regression Cross-validation scores: [0.762 0.765 0.755 0.743 0.771]\n",
            "SVM Mean Accuracy: 0.7618\n",
            "SVM Standard Deviation of Accuracy: 0.010205880657738468\n",
            "Logistic Regression Mean Accuracy: 0.7592\n",
            "Logistic Regression Standard Deviation of Accuracy: 0.009600000000000008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load your data\n",
        "# Assuming X and y are your features and target variables\n",
        "\n",
        "# Initialize models\n",
        "svm_model = SVC(kernel='linear')  # Linear SVM\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform 5-fold cross-validation for SVM\n",
        "svm_scores = cross_val_score(svm_model, chisq_5k, y, cv=kfold)\n",
        "\n",
        "# Perform 5-fold cross-validation for Logistic Regression\n",
        "logistic_scores = cross_val_score(logistic_model, chisq_8k, y, cv=kfold)\n",
        "\n",
        "# Display the cross-validation scores\n",
        "print(\"SVM Cross-validation scores:\", svm_scores)\n",
        "print(\"Logistic Regression Cross-validation scores:\", logistic_scores)\n",
        "\n",
        "# Optionally, you can calculate mean and standard deviation of the scores\n",
        "print(\"SVM Mean Accuracy:\", np.mean(svm_scores))\n",
        "print(\"SVM Standard Deviation of Accuracy:\", np.std(svm_scores))\n",
        "print(\"Logistic Regression Mean Accuracy:\", np.mean(logistic_scores))\n",
        "print(\"Logistic Regression Standard Deviation of Accuracy:\", np.std(logistic_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.6096 - loss: 0.6610\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7570 - loss: 0.4981\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.7686 - loss: 0.4749\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7883 - loss: 0.4516\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.8027 - loss: 0.4221\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7999 - loss: 0.4303\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.8156 - loss: 0.3934\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.8206 - loss: 0.3898\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.8225 - loss: 0.3790\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8269 - loss: 0.3703\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Neural Network Accuracy on Test Set: 0.716\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Assuming chisq_8k has features and y is the output\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(chisq_8k, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Neural Network Accuracy on Test Set:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'keras.optimizers' has no attribute 'experimental'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[78], line 33\u001b[0m\n\u001b[0;32m     23\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241m.\u001b[39mAdagrad(\n\u001b[0;32m     34\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     35\u001b[0m     initial_accumulator_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     36\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-07\u001b[39m,\n\u001b[0;32m     37\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m     38\u001b[0m     clipnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     39\u001b[0m     clipvalue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m     global_clipnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     41\u001b[0m     use_ema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     42\u001b[0m     ema_momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m,\n\u001b[0;32m     43\u001b[0m     ema_overwrite_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m     jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     45\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdagrad\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# # Build a simple neural network model\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# model = \"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# model = Sequential()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'experimental'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming chisq_8k has features and y is the output\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(chisq_8k, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# \n",
        "# \n",
        "# \n",
        "# This is Custom Optimizer\n",
        "# \n",
        "# \n",
        "# \n",
        "\n",
        "optimizer = tf.keras.optimizers.experimental.Adagrad(\n",
        "    learning_rate=0.1,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    weight_decay=0.001,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Adagrad',\n",
        ")\n",
        "\n",
        "\n",
        "# # Build a simple neural network model\n",
        "# model = \"\"\n",
        "# model = Sequential()\n",
        "# model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train, \n",
        "    epochs=50, batch_size=32, \n",
        "    validation_split=0.15,  # Using a portion of training set for validation\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Neural Network Accuracy on Test Set:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
