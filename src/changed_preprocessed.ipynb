{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8UEb9OHI4gNS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from langdetect import detect\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OutputSentiment\n",
              "positive    2537\n",
              "negative    2463\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"../Dataset/IMDB Dataset.csv\")\n",
        "df.head()\n",
        "df = df.rename(columns={'review': 'OriginalReviews'})\n",
        "df = df.rename(columns={'sentiment': 'OutputSentiment'})\n",
        "df_subset = df.sample(n=5000).reset_index(drop=True)\n",
        "df_subset.head()\n",
        "df_subset['OutputSentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Function to remove HTML tags from a text\n",
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    return soup.get_text()\n",
        "\n",
        "#Stopwords removal\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stopwords from a text\n",
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "# Function to remove URLs from a text\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub('', text)\n",
        "\n",
        "# Function to filter non-English comments\n",
        "def filter_non_english(text):\n",
        "    try:\n",
        "        return detect(text) == 'en'\n",
        "    except:\n",
        "        return False\n",
        "    \n",
        "# Define a function to remove sequences of numbers from a string\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdidd\\AppData\\Local\\Temp\\ipykernel_19492\\3685019402.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, 'html.parser')\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Remove numbers from the 'OriginalReviews' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_numbers)\n",
        "\n",
        "#Remove punctuations\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "\n",
        "# Apply the remove_stopwords function to the 'reviews' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_stopwords)\n",
        "\n",
        "# Apply the remove_html_tags function to the 'text' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_html_tags)\n",
        "\n",
        "# Apply the remove_urls function to the 'reviews' column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(remove_urls)\n",
        "\n",
        "# Create a boolean mask for non-English reviews\n",
        "mask = df_subset['OriginalReviews'].apply(filter_non_english)\n",
        "\n",
        "# Create a new DataFrame containing only English reviews\n",
        "df_subset = df_subset[mask]\n",
        "\n",
        "nltk.download('wordnet')\n",
        "# Lemmatization function\n",
        "def lemmatize_column(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply the function to the specific column\n",
        "df_subset['OriginalReviews'] = df_subset['OriginalReviews'].apply(lemmatize_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_subset.to_csv(\"../csv/Preprocessed_data.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction Using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed = pd.read_csv('../csv/Preprocessed_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_features_to_keep = 13000\n",
        "\n",
        "# Create a pipeline with TfidfVectorizer and SelectKBest\n",
        "pipeline = make_pipeline(TfidfVectorizer(), SelectKBest(f_classif, k=num_features_to_keep))\n",
        "\n",
        "# Fit and transform your data\n",
        "X_transformed = pipeline.fit_transform(preprocessed['OriginalReviews'], preprocessed['OutputSentiment'])\n",
        "\n",
        "# Get the selected feature names\n",
        "selected_feature_names = pipeline.named_steps['tfidfvectorizer'].get_feature_names_out()[pipeline.named_steps['selectkbest'].get_support()]\n",
        "\n",
        "# Create a DataFrame with the selected features\n",
        "selected_features_df = pd.DataFrame(X_transformed.toarray(), columns=selected_feature_names)\n",
        "\n",
        "# Concatenate the existing DataFrame with the new selected features DataFrame\n",
        "tfidf_df_13k = pd.concat([preprocessed, selected_features_df], axis=1)\n",
        "\n",
        "tfidf_df_13k.head()\n",
        "\n",
        "tfidf_df_13k.to_csv(\"../csv/tfidf_df_13k.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CONNOTATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\sdidd\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download the VADER lexicon (run this once)\n",
        "nltk.download('vader_lexicon')\n",
        "delimiter = '\\t'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "positive = pd.read_csv(r'..\\Connotations\\positive-words.txt', sep=delimiter, names=['words'])\n",
        "negative = pd.read_csv(r'..\\Connotations\\negative-words.txt', sep=delimiter, names=['words'])\n",
        "connotations = pd.read_csv(r\"..\\Connotations\\connotations.csv\")\n",
        "\n",
        "word_emotion_map = dict(zip(connotations['word'], connotations['emotion']))\n",
        "\n",
        "def update_counts(review):\n",
        "    positive_count = sum(1 for word in review.split() if word in word_emotion_map and word_emotion_map[word] == 'positive')\n",
        "    negative_count = sum(1 for word in review.split() if word in word_emotion_map and word_emotion_map[word] == 'negative')\n",
        "    return positive_count, negative_count\n",
        "\n",
        "tfidf_df_13k[['Positive_Connotation_Count', 'Negative_Connotation_Count']] = tfidf_df_13k['OriginalReviews'].apply(update_counts).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load positive and negative words from files\n",
        "positive_words_df = pd.read_csv(r'..\\Connotations\\positive-words.txt', header=None, names=['words'])\n",
        "negative_words_df = pd.read_csv(r'..\\Connotations\\negative-words.txt', header=None, names=['words'])\n",
        "\n",
        "# Convert DataFrame columns to sets\n",
        "positive_words = set(positive_words_df['words'].tolist())\n",
        "negative_words = set(negative_words_df['words'].tolist())\n",
        "\n",
        "# Assuming 'tfidf_df_13k' is your DataFrame\n",
        "# Define a function to update counts based on positive and negative words\n",
        "def update_word_counts(review):\n",
        "    positive_count = sum(1 for word in review.split() if word in positive_words)\n",
        "    negative_count = sum(1 for word in review.split() if word in negative_words)\n",
        "    return positive_count, negative_count\n",
        "\n",
        "# Apply the function to the 'OriginalReviews' column and unpack the result into two new columns\n",
        "tfidf_df_13k[['Positive_Word_Count', 'Negative_Word_Count']] = tfidf_df_13k['OriginalReviews'].apply(update_word_counts).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "# Use VADER for sentiment analysis\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(review):\n",
        "    scores = sid.polarity_scores(review)\n",
        "    return scores['pos'] *100, scores['neg'] * 100\n",
        "\n",
        "# Apply the function to the 'OriginalReviews' column and unpack the result into two new columns\n",
        "tfidf_df_13k[['Positive_VADER_Count', 'Negative_VADER_Count']] = tfidf_df_13k['OriginalReviews'].apply(vader_sentiment).tolist()\n",
        "\n",
        "tfidf_df_13k.to_csv(\"../csv/tfidf_df_13k_connotations_vader.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = tfidf_df_13k.iloc[4993]['OriginalReviews']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_df_13k = pd.read_csv(\"../csv/tfidf_df_13k.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_df_13k_connotations = pd.read_csv('../csv/tfidf_df_13k_connotations_vader.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1PSHjJbnJcoJ"
      },
      "outputs": [],
      "source": [
        "tfidf_df_13k_connotations = tfidf_df_13k_connotations.drop('Unnamed: 0',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalReviews</th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>00</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>0230</th>\n",
              "      <th>05</th>\n",
              "      <th>09</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>zz</th>\n",
              "      <th>æon</th>\n",
              "      <th>éloge</th>\n",
              "      <th>über</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>really liked movie ! Even though n't anything ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>week , thought would fun catch Corey Haim , se...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>20.4</td>\n",
              "      <td>17.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zero Day film people gotten see , shame is . &lt;...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>31.4</td>\n",
              "      <td>14.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>first murder scene one best murder film histor...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>17.3</td>\n",
              "      <td>22.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watched film recently first time 30 year pleas...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>really enjoyed movie dog becomes Duke . would ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>36.7</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>thought going lousy movie , honestly , mean , ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>17.4</td>\n",
              "      <td>24.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>* * * * Spitfire ( 1934 ) John Cromwell ~ Kath...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>surfing IMDb one day , stumbled across `` Curi...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>24.6</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Rating : * 1/2 * * * * &lt; br / &gt; &lt; br / &gt; `` Ne...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>12.3</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows × 13008 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        OriginalReviews OutputSentiment   00  \\\n",
              "0     really liked movie ! Even though n't anything ...        positive  0.0   \n",
              "1     week , thought would fun catch Corey Haim , se...        negative  0.0   \n",
              "2     Zero Day film people gotten see , shame is . <...        positive  0.0   \n",
              "3     first murder scene one best murder film histor...        positive  0.0   \n",
              "4     watched film recently first time 30 year pleas...        positive  0.0   \n",
              "...                                                 ...             ...  ...   \n",
              "4991  really enjoyed movie dog becomes Duke . would ...        positive  0.0   \n",
              "4992  thought going lousy movie , honestly , mean , ...        positive  0.0   \n",
              "4993  * * * * Spitfire ( 1934 ) John Cromwell ~ Kath...        negative  0.0   \n",
              "4994  surfing IMDb one day , stumbled across `` Curi...        positive  0.0   \n",
              "4995  Rating : * 1/2 * * * * < br / > < br / > `` Ne...        negative  0.0   \n",
              "\n",
              "      007   01   02  0230   05   09       10  ...   zz  æon  éloge  über  \\\n",
              "0     0.0  0.0  0.0   0.0  0.0  0.0  0.11301  ...  0.0  0.0    0.0   0.0   \n",
              "1     0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "2     0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "3     0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "4     0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "...   ...  ...  ...   ...  ...  ...      ...  ...  ...  ...    ...   ...   \n",
              "4991  0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "4992  0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "4993  0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "4994  0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "4995  0.0  0.0  0.0   0.0  0.0  0.0  0.00000  ...  0.0  0.0    0.0   0.0   \n",
              "\n",
              "      Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0                             32                          11   \n",
              "1                             47                          49   \n",
              "2                             35                          21   \n",
              "3                             12                           9   \n",
              "4                             41                          19   \n",
              "...                          ...                         ...   \n",
              "4991                          16                           5   \n",
              "4992                          23                          26   \n",
              "4993                          31                          14   \n",
              "4994                          46                          30   \n",
              "4995                          52                          45   \n",
              "\n",
              "      Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                       7                    0                  20.6   \n",
              "1                      12                   15                  20.4   \n",
              "2                      13                    5                  31.4   \n",
              "3                       3                    3                  17.3   \n",
              "4                      10                    9                  18.8   \n",
              "...                   ...                  ...                   ...   \n",
              "4991                    5                    1                  36.7   \n",
              "4992                    4                   12                  17.4   \n",
              "4993                    6                    6                  21.3   \n",
              "4994                    9                   11                  24.6   \n",
              "4995                    7                   20                  12.3   \n",
              "\n",
              "      Negative_VADER_Count  \n",
              "0                      8.1  \n",
              "1                     17.4  \n",
              "2                     14.3  \n",
              "3                     22.2  \n",
              "4                     16.4  \n",
              "...                    ...  \n",
              "4991                   6.2  \n",
              "4992                  24.1  \n",
              "4993                   3.9  \n",
              "4994                   9.7  \n",
              "4995                  22.1  \n",
              "\n",
              "[4996 rows x 13008 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_df_13k_connotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "uTeIZqyGNoLJ",
        "outputId": "ec0a348c-7c08-45a6-a607-4fe270099f03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OutputSentiment</th>\n",
              "      <th>00</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>0230</th>\n",
              "      <th>05</th>\n",
              "      <th>09</th>\n",
              "      <th>10</th>\n",
              "      <th>1000</th>\n",
              "      <th>...</th>\n",
              "      <th>zords</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucco</th>\n",
              "      <th>zuckerman</th>\n",
              "      <th>zunz</th>\n",
              "      <th>zz</th>\n",
              "      <th>æon</th>\n",
              "      <th>éloge</th>\n",
              "      <th>über</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  OutputSentiment   00  007   01   02  0230   05   09       10  1000  ...  \\\n",
              "0        positive  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.11301   0.0  ...   \n",
              "1        negative  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.00000   0.0  ...   \n",
              "2        positive  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.00000   0.0  ...   \n",
              "3        positive  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.00000   0.0  ...   \n",
              "4        positive  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.00000   0.0  ...   \n",
              "\n",
              "   zords  zorro   zu  zucco  zuckerman  zunz   zz  æon  éloge  über  \n",
              "0    0.0    0.0  0.0    0.0        0.0   0.0  0.0  0.0    0.0   0.0  \n",
              "1    0.0    0.0  0.0    0.0        0.0   0.0  0.0  0.0    0.0   0.0  \n",
              "2    0.0    0.0  0.0    0.0        0.0   0.0  0.0  0.0    0.0   0.0  \n",
              "3    0.0    0.0  0.0    0.0        0.0   0.0  0.0  0.0    0.0   0.0  \n",
              "4    0.0    0.0  0.0    0.0        0.0   0.0  0.0  0.0    0.0   0.0  \n",
              "\n",
              "[5 rows x 13001 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_statistical = tfidf_df_13k_connotations.drop(columns=['OriginalReviews','Positive_Connotation_Count','Negative_Connotation_Count','Positive_Word_Count','Negative_Word_Count','Positive_VADER_Count','Negative_VADER_Count'], axis=1)\n",
        "df_statistical.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dd-FWJp3N_ug"
      },
      "outputs": [],
      "source": [
        "label = LabelEncoder()\n",
        "df_statistical['OutputSentiment'] = label.fit_transform(df_statistical['OutputSentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CHI SQAURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>1000</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>10th</th>\n",
              "      <th>16</th>\n",
              "      <th>180</th>\n",
              "      <th>1800s</th>\n",
              "      <th>1900s</th>\n",
              "      <th>...</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucco</th>\n",
              "      <th>zuckerman</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>20.4</td>\n",
              "      <td>17.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>31.4</td>\n",
              "      <td>14.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>17.3</td>\n",
              "      <td>22.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   007   01  1000  101  102  10th   16  180  1800s  1900s  ...  zorro   zu  \\\n",
              "0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0    0.0    0.0  ...    0.0  0.0   \n",
              "1  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0    0.0    0.0  ...    0.0  0.0   \n",
              "2  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0    0.0    0.0  ...    0.0  0.0   \n",
              "3  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0    0.0    0.0  ...    0.0  0.0   \n",
              "4  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0    0.0    0.0  ...    0.0  0.0   \n",
              "\n",
              "   zucco  zuckerman  Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0    0.0        0.0                          32                          11   \n",
              "1    0.0        0.0                          47                          49   \n",
              "2    0.0        0.0                          35                          21   \n",
              "3    0.0        0.0                          12                           9   \n",
              "4    0.0        0.0                          41                          19   \n",
              "\n",
              "   Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                    7                    0                  20.6   \n",
              "1                   12                   15                  20.4   \n",
              "2                   13                    5                  31.4   \n",
              "3                    3                    3                  17.3   \n",
              "4                   10                    9                  18.8   \n",
              "\n",
              "   Negative_VADER_Count  \n",
              "0                   8.1  \n",
              "1                  17.4  \n",
              "2                  14.3  \n",
              "3                  22.2  \n",
              "4                  16.4  \n",
              "\n",
              "[5 rows x 5006 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This will get the top 5000 relavant features out of the sample\n",
        "chi2_selector = SelectKBest(chi2, k=5000)\n",
        "\n",
        "# This will transform the dataset i.e, it will reduce the dimensions by just considering the relavant features only\n",
        "X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "y = df_statistical['OutputSentiment']\n",
        "X_5000 = chi2_selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "\n",
        "chisq_5k = X[selected_feature_names]\n",
        "chisq_5k.head()\n",
        "\n",
        "chisq_5k = pd.concat([chisq_5k,tfidf_df_13k_connotations.iloc[:, -6:]],axis=1)\n",
        "chisq_5k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>05</th>\n",
              "      <th>09</th>\n",
              "      <th>1000</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>10th</th>\n",
              "      <th>...</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucco</th>\n",
              "      <th>zuckerman</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>20.4</td>\n",
              "      <td>17.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>31.4</td>\n",
              "      <td>14.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>17.3</td>\n",
              "      <td>22.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  007   01   02   05   09  1000  101  102  10th  ...  zorro   zu  zucco  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0    0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0    0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0    0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0    0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0    0.0   \n",
              "\n",
              "   zuckerman  Positive_Connotation_Count  Negative_Connotation_Count  \\\n",
              "0        0.0                          32                          11   \n",
              "1        0.0                          47                          49   \n",
              "2        0.0                          35                          21   \n",
              "3        0.0                          12                           9   \n",
              "4        0.0                          41                          19   \n",
              "\n",
              "   Positive_Word_Count  Negative_Word_Count  Positive_VADER_Count  \\\n",
              "0                    7                    0                  20.6   \n",
              "1                   12                   15                  20.4   \n",
              "2                   13                    5                  31.4   \n",
              "3                    3                    3                  17.3   \n",
              "4                   10                    9                  18.8   \n",
              "\n",
              "   Negative_VADER_Count  \n",
              "0                   8.1  \n",
              "1                  17.4  \n",
              "2                  14.3  \n",
              "3                  22.2  \n",
              "4                  16.4  \n",
              "\n",
              "[5 rows x 8006 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This will get the top 5000 relavant features out of the sample\n",
        "chi2_selector = SelectKBest(chi2, k=8000)\n",
        "\n",
        "# This will transform the dataset i.e, it will reduce the dimensions by just considering the relavant features only\n",
        "X = df_statistical.drop(columns=['OutputSentiment'])\n",
        "y = df_statistical['OutputSentiment']\n",
        "X_8000 = chi2_selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "\n",
        "chisq_8k = X[selected_feature_names]\n",
        "chisq_8k.head()\n",
        "\n",
        "chisq_8k = pd.concat([chisq_8k,tfidf_df_13k_connotations.iloc[:, -6:]],axis=1)\n",
        "chisq_8k.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>05</th>\n",
              "      <th>09</th>\n",
              "      <th>1000</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>10th</th>\n",
              "      <th>...</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucco</th>\n",
              "      <th>zuckerman</th>\n",
              "      <th>Positive_Connotation_Count</th>\n",
              "      <th>Negative_Connotation_Count</th>\n",
              "      <th>Positive_Word_Count</th>\n",
              "      <th>Negative_Word_Count</th>\n",
              "      <th>Positive_VADER_Count</th>\n",
              "      <th>Negative_VADER_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>20.4</td>\n",
              "      <td>17.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>31.4</td>\n",
              "      <td>14.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>17.3</td>\n",
              "      <td>22.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>36.7</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>17.4</td>\n",
              "      <td>24.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>24.6</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>12.3</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows × 8006 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       00  007   01   02   05   09  1000  101  102  10th  ...  zorro   zu  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...   ...  ...  ...   ...  ...    ...  ...   \n",
              "4991  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "4992  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "4993  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "4994  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "4995  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              "\n",
              "      zucco  zuckerman  Positive_Connotation_Count  \\\n",
              "0       0.0        0.0                          32   \n",
              "1       0.0        0.0                          47   \n",
              "2       0.0        0.0                          35   \n",
              "3       0.0        0.0                          12   \n",
              "4       0.0        0.0                          41   \n",
              "...     ...        ...                         ...   \n",
              "4991    0.0        0.0                          16   \n",
              "4992    0.0        0.0                          23   \n",
              "4993    0.0        0.0                          31   \n",
              "4994    0.0        0.0                          46   \n",
              "4995    0.0        0.0                          52   \n",
              "\n",
              "      Negative_Connotation_Count  Positive_Word_Count  Negative_Word_Count  \\\n",
              "0                             11                    7                    0   \n",
              "1                             49                   12                   15   \n",
              "2                             21                   13                    5   \n",
              "3                              9                    3                    3   \n",
              "4                             19                   10                    9   \n",
              "...                          ...                  ...                  ...   \n",
              "4991                           5                    5                    1   \n",
              "4992                          26                    4                   12   \n",
              "4993                          14                    6                    6   \n",
              "4994                          30                    9                   11   \n",
              "4995                          45                    7                   20   \n",
              "\n",
              "      Positive_VADER_Count  Negative_VADER_Count  \n",
              "0                     20.6                   8.1  \n",
              "1                     20.4                  17.4  \n",
              "2                     31.4                  14.3  \n",
              "3                     17.3                  22.2  \n",
              "4                     18.8                  16.4  \n",
              "...                    ...                   ...  \n",
              "4991                  36.7                   6.2  \n",
              "4992                  17.4                  24.1  \n",
              "4993                  21.3                   3.9  \n",
              "4994                  24.6                   9.7  \n",
              "4995                  12.3                  22.1  \n",
              "\n",
              "[4996 rows x 8006 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chisq_8k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CHI SQAURE CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes Cross-Validation Scores:\n",
            "[0.754      0.74874875 0.74574575 0.75475475 0.76276276]\n",
            "Mean Accuracy: 0.7532024024024023\n",
            "\n",
            "k-Nearest Neighbors Cross-Validation Scores:\n",
            "[0.694      0.68168168 0.6976977  0.69369369 0.70570571]\n",
            "Mean Accuracy: 0.6945557557557557\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Multinomial Naive Bayes Classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_scores = cross_val_score(nb_classifier, chisq_8k, y, cv=5)\n",
        "\n",
        "print(\"Multinomial Naive Bayes Cross-Validation Scores:\")\n",
        "print(nb_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(nb_scores))\n",
        "\n",
        "# k-Nearest Neighbors Classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_scores = cross_val_score(knn_classifier, chisq_5k, y, cv=5)\n",
        "\n",
        "print(\"\\nk-Nearest Neighbors Cross-Validation Scores:\")\n",
        "print(knn_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(knn_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import cross_val_score, KFold\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# # Load your data\n",
        "# # Assuming X and y are your features and target variables\n",
        "\n",
        "# # Initialize models\n",
        "# svm_model = SVC(kernel='linear')  # Linear SVM\n",
        "# logistic_model = LogisticRegression()\n",
        "\n",
        "# # Initialize KFold cross-validation\n",
        "# kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# # Perform 5-fold cross-validation for SVM\n",
        "# svm_scores = cross_val_score(svm_model, chisq_5k, y, cv=kfold)\n",
        "\n",
        "# # Perform 5-fold cross-validation for Logistic Regression\n",
        "# logistic_scores = cross_val_score(logistic_model, chisq_8k, y, cv=kfold)\n",
        "\n",
        "# # Display the cross-validation scores\n",
        "# print(\"SVM Cross-validation scores:\", svm_scores)\n",
        "# print(\"Logistic Regression Cross-validation scores:\", logistic_scores)\n",
        "\n",
        "# # Optionally, you can calculate mean and standard deviation of the scores\n",
        "# print(\"SVM Mean Accuracy:\", np.mean(svm_scores))\n",
        "# print(\"SVM Standard Deviation of Accuracy:\", np.std(svm_scores))\n",
        "# print(\"Logistic Regression Mean Accuracy:\", np.mean(logistic_scores))\n",
        "# print(\"Logistic Regression Standard Deviation of Accuracy:\", np.std(logistic_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\sdidd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "125/125 [==============================] - 3s 13ms/step - loss: 0.3203 - accuracy: 0.8501\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0086 - accuracy: 0.9982\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 9.9659e-04 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 4.3728e-04 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 2.6657e-04 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.8240e-04 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.3302e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 1.0127e-04 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 7.9529e-05 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 6.4026e-05 - accuracy: 1.0000\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Neural Network Accuracy on Test Set: 0.936\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Assuming chisq_8k has features and y is the output\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(chisq_8k, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Neural Network Accuracy on Test Set:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "113/113 [==============================] - 3s 17ms/step - loss: 0.3391 - accuracy: 0.8401 - val_loss: 0.2019 - val_accuracy: 0.9150\n",
            "Epoch 2/50\n",
            "113/113 [==============================] - 2s 13ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.2070 - val_accuracy: 0.9100\n",
            "Epoch 3/50\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9075\n",
            "Epoch 4/50\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 5.5259e-04 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9075\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Neural Network Accuracy on Test Set: 0.925\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming chisq_8k has features and y is the output\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(chisq_8k, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train, \n",
        "    epochs=50, batch_size=32, \n",
        "    validation_split=0.1,  # Using a portion of training set for validation\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Neural Network Accuracy on Test Set:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
